{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#device selection\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,nb_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = 0\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nb_channels, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(64, 128, 4, 2, 2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(256, 1, 4, 1, 0, bias=False),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            #nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, nb_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = 0\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( input_dim, 128 * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(128 * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(128 * 4, 128 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128 * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( 128 * 2, 128 , 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128 ),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( 128 *1, nb_channels, 4, 2, 3, bias=False),\n",
    "            #nn.BatchNorm2d(ngf),\n",
    "            #nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            #nn.ConvTranspose2d( 128, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "disc=Discriminator(1)\n",
    "gen=Generator(100,1)\n",
    "\n",
    "noise=torch.randn(32,100,1,1)\n",
    "out=gen(noise)\n",
    "print(out.size())\n",
    "out2=disc(out)\n",
    "print(out2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomasaqa/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#Hyper parameters\n",
    "lr = 2*10**(-4)\n",
    "momentum=0.5\n",
    "batch_size=128\n",
    "\n",
    "input_dim=64\n",
    "image_dim=28*28\n",
    "nb_channels=1\n",
    "\n",
    "num_epoch=50\n",
    "\n",
    "disc=Discriminator(nb_channels).to(device)\n",
    "gen=Generator(input_dim, nb_channels).to(device)\n",
    "\n",
    "#fixed noise\n",
    "fixed_noise = torch.randn(batch_size,input_dim,1,1).to(device)\n",
    "\n",
    "#writer\n",
    "writer_fake = SummaryWriter(f\"runs/DCGAN_MNIST/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/DCGAN_MNIST/real\")\n",
    "\n",
    "transformations=transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))]\n",
    "    )\n",
    "\n",
    "dataset = datasets.MNIST(root=\"dataset/\",transform=transformations, download=True) #Chargement du dataset\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True) #batch creation\n",
    "\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "step=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50Loss D: 0.5660, Loss G: 0.3901\n",
      "Epoch [0/50Loss D: 0.5516, Loss G: 0.4035\n",
      "Epoch [0/50Loss D: 0.5701, Loss G: 0.3858\n",
      "Epoch [0/50Loss D: 0.7946, Loss G: 0.2287\n",
      "Epoch [0/50Loss D: 0.4930, Loss G: 0.4683\n",
      "Epoch [0/50Loss D: 0.5228, Loss G: 0.4338\n",
      "Epoch [0/50Loss D: 0.6191, Loss G: 0.3429\n",
      "Epoch [0/50Loss D: 0.4957, Loss G: 0.4649\n",
      "Epoch [0/50Loss D: 0.6589, Loss G: 0.3121\n",
      "Epoch [0/50Loss D: 0.6032, Loss G: 0.3564\n",
      "Epoch [0/50Loss D: 0.5004, Loss G: 0.4592\n",
      "Epoch [0/50Loss D: 0.6037, Loss G: 0.3560\n",
      "Epoch [0/50Loss D: 0.5006, Loss G: 0.4590\n",
      "Epoch [0/50Loss D: 0.5669, Loss G: 0.3888\n",
      "Epoch [0/50Loss D: 0.5343, Loss G: 0.4217\n",
      "Epoch [0/50Loss D: 0.5721, Loss G: 0.3840\n",
      "Epoch [0/50Loss D: 0.5522, Loss G: 0.4030\n",
      "Epoch [0/50Loss D: 0.5462, Loss G: 0.4091\n",
      "Epoch [0/50Loss D: 0.5547, Loss G: 0.4005\n",
      "Epoch [0/50Loss D: 0.5510, Loss G: 0.4041\n",
      "Epoch [0/50Loss D: 0.5597, Loss G: 0.3957\n",
      "Epoch [0/50Loss D: 0.5604, Loss G: 0.3948\n",
      "Epoch [0/50Loss D: 0.6075, Loss G: 0.3526\n",
      "Epoch [0/50Loss D: 0.5036, Loss G: 0.4551\n",
      "Epoch [0/50Loss D: 0.5387, Loss G: 0.4170\n",
      "Epoch [0/50Loss D: 0.6394, Loss G: 0.3267\n",
      "Epoch [0/50Loss D: 0.5569, Loss G: 0.3983\n",
      "Epoch [0/50Loss D: 0.5336, Loss G: 0.4220\n",
      "Epoch [0/50Loss D: 0.5649, Loss G: 0.3906\n",
      "Epoch [0/50Loss D: 0.5580, Loss G: 0.3972\n",
      "Epoch [0/50Loss D: 0.5487, Loss G: 0.4066\n",
      "Epoch [0/50Loss D: 0.5680, Loss G: 0.3879\n",
      "Epoch [0/50Loss D: 0.5710, Loss G: 0.3848\n",
      "Epoch [0/50Loss D: 0.5482, Loss G: 0.4070\n",
      "Epoch [0/50Loss D: 0.5509, Loss G: 0.4042\n",
      "Epoch [0/50Loss D: 0.6498, Loss G: 0.3186\n",
      "Epoch [0/50Loss D: 0.6096, Loss G: 0.3506\n",
      "Epoch [0/50Loss D: 0.5300, Loss G: 0.4257\n",
      "Epoch [0/50Loss D: 0.4916, Loss G: 0.4693\n",
      "Epoch [0/50Loss D: 0.5603, Loss G: 0.3951\n",
      "Epoch [0/50Loss D: 0.4579, Loss G: 0.5122\n",
      "Epoch [0/50Loss D: 0.6083, Loss G: 0.3522\n",
      "Epoch [0/50Loss D: 0.5231, Loss G: 0.4336\n",
      "Epoch [0/50Loss D: 0.5586, Loss G: 0.3973\n",
      "Epoch [0/50Loss D: 0.5804, Loss G: 0.3762\n",
      "Epoch [0/50Loss D: 0.5595, Loss G: 0.3960\n",
      "Epoch [0/50Loss D: 0.5687, Loss G: 0.3875\n",
      "Epoch [0/50Loss D: 0.5086, Loss G: 0.4497\n",
      "Epoch [0/50Loss D: 0.5846, Loss G: 0.3728\n",
      "Epoch [0/50Loss D: 0.5421, Loss G: 0.4134\n",
      "Epoch [0/50Loss D: 0.5594, Loss G: 0.3963\n",
      "Epoch [0/50Loss D: 0.5503, Loss G: 0.4050\n",
      "Epoch [0/50Loss D: 0.5345, Loss G: 0.4212\n",
      "Epoch [0/50Loss D: 0.5563, Loss G: 0.3990\n",
      "Epoch [0/50Loss D: 0.5499, Loss G: 0.4052\n",
      "Epoch [0/50Loss D: 0.5392, Loss G: 0.4162\n",
      "Epoch [0/50Loss D: 0.5422, Loss G: 0.4131\n",
      "Epoch [0/50Loss D: 0.5523, Loss G: 0.4029\n",
      "Epoch [0/50Loss D: 0.5514, Loss G: 0.4038\n",
      "Epoch [0/50Loss D: 0.4556, Loss G: 0.5152\n",
      "Epoch [0/50Loss D: 0.4662, Loss G: 0.5013\n",
      "Epoch [0/50Loss D: 0.5468, Loss G: 0.4092\n",
      "Epoch [0/50Loss D: 0.5778, Loss G: 0.3787\n",
      "Epoch [0/50Loss D: 0.5650, Loss G: 0.3909\n",
      "Epoch [0/50Loss D: 0.5462, Loss G: 0.4091\n",
      "Epoch [0/50Loss D: 0.5460, Loss G: 0.4091\n",
      "Epoch [0/50Loss D: 0.5478, Loss G: 0.4074\n",
      "Epoch [0/50Loss D: 0.5379, Loss G: 0.4174\n",
      "Epoch [0/50Loss D: 0.5557, Loss G: 0.3995\n",
      "Epoch [0/50Loss D: 0.5104, Loss G: 0.4471\n",
      "Epoch [0/50Loss D: 0.5742, Loss G: 0.3819\n",
      "Epoch [0/50Loss D: 0.6059, Loss G: 0.3540\n",
      "Epoch [0/50Loss D: 0.5544, Loss G: 0.4011\n",
      "Epoch [0/50Loss D: 0.5231, Loss G: 0.4334\n",
      "Epoch [0/50Loss D: 0.5499, Loss G: 0.4055\n",
      "Epoch [0/50Loss D: 0.5451, Loss G: 0.4102\n",
      "Epoch [0/50Loss D: 0.5170, Loss G: 0.4399\n",
      "Epoch [0/50Loss D: 0.5735, Loss G: 0.3827\n",
      "Epoch [0/50Loss D: 0.5454, Loss G: 0.4098\n",
      "Epoch [0/50Loss D: 0.9684, Loss G: 0.1559\n",
      "Epoch [0/50Loss D: 0.3928, Loss G: 0.6171\n",
      "Epoch [0/50Loss D: 0.5845, Loss G: 0.3756\n",
      "Epoch [0/50Loss D: 0.5664, Loss G: 0.3906\n",
      "Epoch [0/50Loss D: 0.5168, Loss G: 0.4408\n",
      "Epoch [0/50Loss D: 0.5563, Loss G: 0.3992\n",
      "Epoch [0/50Loss D: 0.5614, Loss G: 0.3940\n",
      "Epoch [0/50Loss D: 0.5558, Loss G: 0.3995\n",
      "Epoch [0/50Loss D: 0.5525, Loss G: 0.4028\n",
      "Epoch [0/50Loss D: 0.5476, Loss G: 0.4075\n",
      "Epoch [0/50Loss D: 0.5671, Loss G: 0.3886\n",
      "Epoch [0/50Loss D: 0.5417, Loss G: 0.4136\n",
      "Epoch [0/50Loss D: 0.5206, Loss G: 0.4363\n",
      "Epoch [0/50Loss D: 0.5581, Loss G: 0.3974\n",
      "Epoch [0/50Loss D: 0.5763, Loss G: 0.3801\n",
      "Epoch [0/50Loss D: 0.5574, Loss G: 0.3983\n",
      "Epoch [0/50Loss D: 0.5584, Loss G: 0.3971\n",
      "Epoch [0/50Loss D: 0.5482, Loss G: 0.4071\n",
      "Epoch [0/50Loss D: 0.5401, Loss G: 0.4153\n",
      "Epoch [0/50Loss D: 0.5544, Loss G: 0.4009\n",
      "Epoch [0/50Loss D: 0.5459, Loss G: 0.4094\n",
      "Epoch [0/50Loss D: 0.5559, Loss G: 0.3994\n",
      "Epoch [0/50Loss D: 0.5494, Loss G: 0.4059\n",
      "Epoch [0/50Loss D: 0.5608, Loss G: 0.3944\n",
      "Epoch [0/50Loss D: 0.5680, Loss G: 0.3877\n",
      "Epoch [0/50Loss D: 0.5626, Loss G: 0.3930\n",
      "Epoch [0/50Loss D: 0.5308, Loss G: 0.4250\n",
      "Epoch [0/50Loss D: 0.5215, Loss G: 0.4350\n",
      "Epoch [0/50Loss D: 0.5503, Loss G: 0.4054\n",
      "Epoch [0/50Loss D: 0.6724, Loss G: 0.3091\n",
      "Epoch [0/50Loss D: 0.6051, Loss G: 0.3666\n",
      "Epoch [0/50Loss D: 0.5845, Loss G: 0.3763\n",
      "Epoch [0/50Loss D: 0.5106, Loss G: 0.4573\n",
      "Epoch [0/50Loss D: 0.4158, Loss G: 0.5895\n",
      "Epoch [0/50Loss D: 0.5289, Loss G: 0.4323\n",
      "Epoch [0/50Loss D: 0.4937, Loss G: 0.4770\n",
      "Epoch [0/50Loss D: 0.6482, Loss G: 0.3263\n",
      "Epoch [0/50Loss D: 0.4766, Loss G: 0.4948\n",
      "Epoch [0/50Loss D: 0.5941, Loss G: 0.3696\n",
      "Epoch [0/50Loss D: 0.5814, Loss G: 0.3835\n",
      "Epoch [0/50Loss D: 0.5090, Loss G: 0.4536\n",
      "Epoch [0/50Loss D: 0.5624, Loss G: 0.3946\n",
      "Epoch [0/50Loss D: 0.5809, Loss G: 0.3765\n",
      "Epoch [0/50Loss D: 0.5379, Loss G: 0.4195\n",
      "Epoch [0/50Loss D: 0.5453, Loss G: 0.4108\n",
      "Epoch [0/50Loss D: 0.5683, Loss G: 0.3887\n",
      "Epoch [0/50Loss D: 0.5773, Loss G: 0.3800\n",
      "Epoch [0/50Loss D: 0.5453, Loss G: 0.4119\n",
      "Epoch [0/50Loss D: 0.5487, Loss G: 0.4084\n",
      "Epoch [0/50Loss D: 0.6241, Loss G: 0.3413\n",
      "Epoch [0/50Loss D: 0.5328, Loss G: 0.4247\n",
      "Epoch [0/50Loss D: 0.5516, Loss G: 0.4045\n",
      "Epoch [0/50Loss D: 0.5566, Loss G: 0.3993\n",
      "Epoch [0/50Loss D: 0.5412, Loss G: 0.4144\n",
      "Epoch [0/50Loss D: 0.5451, Loss G: 0.4105\n",
      "Epoch [0/50Loss D: 0.5429, Loss G: 0.4131\n",
      "Epoch [0/50Loss D: 0.5695, Loss G: 0.3870\n",
      "Epoch [0/50Loss D: 0.5414, Loss G: 0.4143\n",
      "Epoch [0/50Loss D: 0.5341, Loss G: 0.4223\n",
      "Epoch [0/50Loss D: 0.5248, Loss G: 0.4314\n",
      "Epoch [0/50Loss D: 0.5325, Loss G: 0.4231\n",
      "Epoch [0/50Loss D: 0.5396, Loss G: 0.4164\n",
      "Epoch [0/50Loss D: 0.5574, Loss G: 0.3982\n",
      "Epoch [0/50Loss D: 0.5378, Loss G: 0.4177\n",
      "Epoch [0/50Loss D: 0.5539, Loss G: 0.4015\n",
      "Epoch [0/50Loss D: 0.5440, Loss G: 0.4114\n",
      "Epoch [0/50Loss D: 0.5578, Loss G: 0.3975\n",
      "Epoch [0/50Loss D: 0.5404, Loss G: 0.4152\n",
      "Epoch [0/50Loss D: 0.5541, Loss G: 0.4012\n",
      "Epoch [0/50Loss D: 0.5559, Loss G: 0.3994\n",
      "Epoch [0/50Loss D: 0.5494, Loss G: 0.4057\n",
      "Epoch [0/50Loss D: 0.5489, Loss G: 0.4065\n",
      "Epoch [0/50Loss D: 0.5535, Loss G: 0.4016\n",
      "Epoch [0/50Loss D: 0.5491, Loss G: 0.4061\n",
      "Epoch [0/50Loss D: 0.5422, Loss G: 0.4131\n",
      "Epoch [0/50Loss D: 0.5114, Loss G: 0.4462\n",
      "Epoch [0/50Loss D: 0.5345, Loss G: 0.4210\n",
      "Epoch [0/50Loss D: 0.5512, Loss G: 0.4040\n",
      "Epoch [0/50Loss D: 0.5401, Loss G: 0.4151\n",
      "Epoch [0/50Loss D: 0.5450, Loss G: 0.4101\n",
      "Epoch [0/50Loss D: 0.5549, Loss G: 0.4002\n",
      "Epoch [0/50Loss D: 0.5680, Loss G: 0.3875\n",
      "Epoch [0/50Loss D: 0.5699, Loss G: 0.3857\n",
      "Epoch [0/50Loss D: 0.5530, Loss G: 0.4021\n",
      "Epoch [0/50Loss D: 0.5442, Loss G: 0.4108\n",
      "Epoch [0/50Loss D: 0.6107, Loss G: 0.3504\n",
      "Epoch [0/50Loss D: 0.5368, Loss G: 0.4190\n",
      "Epoch [0/50Loss D: 0.5173, Loss G: 0.4397\n",
      "Epoch [0/50Loss D: 0.5438, Loss G: 0.4125\n",
      "Epoch [0/50Loss D: 0.5031, Loss G: 0.4561\n",
      "Epoch [0/50Loss D: 0.5592, Loss G: 0.3979\n",
      "Epoch [0/50Loss D: 0.5279, Loss G: 0.4289\n",
      "Epoch [0/50Loss D: 0.5650, Loss G: 0.3910\n",
      "Epoch [0/50Loss D: 0.5493, Loss G: 0.4067\n",
      "Epoch [0/50Loss D: 0.5542, Loss G: 0.4010\n",
      "Epoch [0/50Loss D: 0.5540, Loss G: 0.4015\n",
      "Epoch [0/50Loss D: 0.5419, Loss G: 0.4147\n",
      "Epoch [0/50Loss D: 0.5291, Loss G: 0.4276\n",
      "Epoch [0/50Loss D: 0.5006, Loss G: 0.4596\n",
      "Epoch [0/50Loss D: 0.5017, Loss G: 0.4586\n",
      "Epoch [0/50Loss D: 0.6184, Loss G: 0.3457\n",
      "Epoch [0/50Loss D: 0.6896, Loss G: 0.3009\n",
      "Epoch [0/50Loss D: 0.4666, Loss G: 0.5146\n",
      "Epoch [0/50Loss D: 0.5170, Loss G: 0.4491\n",
      "Epoch [0/50Loss D: 0.6072, Loss G: 0.3562\n",
      "Epoch [0/50Loss D: 0.5813, Loss G: 0.3789\n",
      "Epoch [0/50Loss D: 0.5796, Loss G: 0.3795\n",
      "Epoch [0/50Loss D: 0.4798, Loss G: 0.4874\n",
      "Epoch [0/50Loss D: 0.5781, Loss G: 0.3805\n",
      "Epoch [1/50Loss D: 0.5849, Loss G: 0.3752\n",
      "Epoch [1/50Loss D: 0.5791, Loss G: 0.3794\n",
      "Epoch [1/50Loss D: 0.5563, Loss G: 0.4007\n",
      "Epoch [1/50Loss D: 0.5111, Loss G: 0.4473\n",
      "Epoch [1/50Loss D: 0.5078, Loss G: 0.4512\n",
      "Epoch [1/50Loss D: 0.5364, Loss G: 0.4208\n",
      "Epoch [1/50Loss D: 0.5028, Loss G: 0.4589\n",
      "Epoch [1/50Loss D: 0.5137, Loss G: 0.4455\n",
      "Epoch [1/50Loss D: 0.5529, Loss G: 0.4038\n",
      "Epoch [1/50Loss D: 0.5781, Loss G: 0.3790\n",
      "Epoch [1/50Loss D: 0.5610, Loss G: 0.3959\n",
      "Epoch [1/50Loss D: 0.5253, Loss G: 0.4318\n",
      "Epoch [1/50Loss D: 0.5550, Loss G: 0.4010\n",
      "Epoch [1/50Loss D: 0.5437, Loss G: 0.4129\n",
      "Epoch [1/50Loss D: 0.5389, Loss G: 0.4169\n",
      "Epoch [1/50Loss D: 0.5449, Loss G: 0.4105\n",
      "Epoch [1/50Loss D: 0.5504, Loss G: 0.4053\n",
      "Epoch [1/50Loss D: 0.5629, Loss G: 0.3929\n",
      "Epoch [1/50Loss D: 0.5574, Loss G: 0.3982\n",
      "Epoch [1/50Loss D: 0.5519, Loss G: 0.4035\n",
      "Epoch [1/50Loss D: 0.5478, Loss G: 0.4074\n",
      "Epoch [1/50Loss D: 0.5468, Loss G: 0.4085\n",
      "Epoch [1/50Loss D: 0.5429, Loss G: 0.4124\n",
      "Epoch [1/50Loss D: 0.5516, Loss G: 0.4037\n",
      "Epoch [1/50Loss D: 0.5456, Loss G: 0.4094\n",
      "Epoch [1/50Loss D: 0.5461, Loss G: 0.4090\n",
      "Epoch [1/50Loss D: 0.5566, Loss G: 0.3986\n",
      "Epoch [1/50Loss D: 0.5480, Loss G: 0.4071\n",
      "Epoch [1/50Loss D: 0.5520, Loss G: 0.4030\n",
      "Epoch [1/50Loss D: 0.5472, Loss G: 0.4078\n",
      "Epoch [1/50Loss D: 0.5499, Loss G: 0.4052\n",
      "Epoch [1/50Loss D: 0.5503, Loss G: 0.4047\n",
      "Epoch [1/50Loss D: 0.5533, Loss G: 0.4017\n",
      "Epoch [1/50Loss D: 0.5567, Loss G: 0.3984\n",
      "Epoch [1/50Loss D: 0.5426, Loss G: 0.4124\n",
      "Epoch [1/50Loss D: 0.5468, Loss G: 0.4082\n",
      "Epoch [1/50Loss D: 0.5400, Loss G: 0.4150\n",
      "Epoch [1/50Loss D: 0.5535, Loss G: 0.4014\n",
      "Epoch [1/50Loss D: 0.5453, Loss G: 0.4096\n",
      "Epoch [1/50Loss D: 0.5512, Loss G: 0.4037\n",
      "Epoch [1/50Loss D: 0.5487, Loss G: 0.4062\n",
      "Epoch [1/50Loss D: 0.5536, Loss G: 0.4013\n",
      "Epoch [1/50Loss D: 0.5493, Loss G: 0.4055\n",
      "Epoch [1/50Loss D: 0.5496, Loss G: 0.4052\n",
      "Epoch [1/50Loss D: 0.5463, Loss G: 0.4088\n",
      "Epoch [1/50Loss D: 0.5477, Loss G: 0.4071\n",
      "Epoch [1/50Loss D: 0.5517, Loss G: 0.4032\n",
      "Epoch [1/50Loss D: 0.5487, Loss G: 0.4062\n",
      "Epoch [1/50Loss D: 0.5494, Loss G: 0.4055\n",
      "Epoch [1/50Loss D: 0.5491, Loss G: 0.4057\n",
      "Epoch [1/50Loss D: 0.5513, Loss G: 0.4035\n",
      "Epoch [1/50Loss D: 0.5509, Loss G: 0.4040\n",
      "Epoch [1/50Loss D: 0.5462, Loss G: 0.4088\n",
      "Epoch [1/50Loss D: 0.5472, Loss G: 0.4077\n",
      "Epoch [1/50Loss D: 0.5511, Loss G: 0.4037\n",
      "Epoch [1/50Loss D: 0.5463, Loss G: 0.4086\n",
      "Epoch [1/50Loss D: 0.5489, Loss G: 0.4060\n",
      "Epoch [1/50Loss D: 0.5340, Loss G: 0.4212\n",
      "Epoch [1/50Loss D: 0.5505, Loss G: 0.4044\n",
      "Epoch [1/50Loss D: 0.5475, Loss G: 0.4073\n",
      "Epoch [1/50Loss D: 0.5550, Loss G: 0.3998\n",
      "Epoch [1/50Loss D: 0.5211, Loss G: 0.4351\n",
      "Epoch [1/50Loss D: 0.5610, Loss G: 0.3940\n",
      "Epoch [1/50Loss D: 0.5648, Loss G: 0.3904\n",
      "Epoch [1/50Loss D: 0.5408, Loss G: 0.4143\n",
      "Epoch [1/50Loss D: 0.5564, Loss G: 0.3985\n",
      "Epoch [1/50Loss D: 0.5494, Loss G: 0.4055\n",
      "Epoch [1/50Loss D: 0.5444, Loss G: 0.4105\n",
      "Epoch [1/50Loss D: 0.5486, Loss G: 0.4062\n",
      "Epoch [1/50Loss D: 0.5643, Loss G: 0.3909\n",
      "Epoch [1/50Loss D: 0.5275, Loss G: 0.4282\n",
      "Epoch [1/50Loss D: 0.5580, Loss G: 0.3971\n",
      "Epoch [1/50Loss D: 0.5443, Loss G: 0.4106\n",
      "Epoch [1/50Loss D: 0.5595, Loss G: 0.3955\n",
      "Epoch [1/50Loss D: 0.5308, Loss G: 0.4246\n",
      "Epoch [1/50Loss D: 0.6031, Loss G: 0.3558\n",
      "Epoch [1/50Loss D: 0.5565, Loss G: 0.3984\n",
      "Epoch [1/50Loss D: 0.5600, Loss G: 0.3951\n",
      "Epoch [1/50Loss D: 0.5437, Loss G: 0.4112\n",
      "Epoch [1/50Loss D: 0.5562, Loss G: 0.3987\n",
      "Epoch [1/50Loss D: 0.5547, Loss G: 0.4003\n",
      "Epoch [1/50Loss D: 0.5075, Loss G: 0.4502\n",
      "Epoch [1/50Loss D: 0.5741, Loss G: 0.3817\n",
      "Epoch [1/50Loss D: 0.5864, Loss G: 0.3708\n",
      "Epoch [1/50Loss D: 0.5448, Loss G: 0.4102\n",
      "Epoch [1/50Loss D: 0.5567, Loss G: 0.3986\n",
      "Epoch [1/50Loss D: 0.4697, Loss G: 0.4963\n",
      "Epoch [1/50Loss D: 0.6080, Loss G: 0.3527\n",
      "Epoch [1/50Loss D: 1.1307, Loss G: 0.1123\n",
      "Epoch [1/50Loss D: 0.4420, Loss G: 0.5820\n",
      "Epoch [1/50Loss D: 0.7217, Loss G: 0.2759\n",
      "Epoch [1/50Loss D: 0.4808, Loss G: 0.5190\n",
      "Epoch [1/50Loss D: 0.6143, Loss G: 0.3673\n",
      "Epoch [1/50Loss D: 0.5104, Loss G: 0.4738\n",
      "Epoch [1/50Loss D: 0.7296, Loss G: 0.2938\n",
      "Epoch [1/50Loss D: 0.5254, Loss G: 0.4384\n",
      "Epoch [1/50Loss D: 0.5289, Loss G: 0.4332\n",
      "Epoch [1/50Loss D: 0.5784, Loss G: 0.3805\n",
      "Epoch [1/50Loss D: 0.5969, Loss G: 0.3644\n",
      "Epoch [1/50Loss D: 0.5525, Loss G: 0.4057\n",
      "Epoch [1/50Loss D: 0.5436, Loss G: 0.4136\n",
      "Epoch [1/50Loss D: 0.5551, Loss G: 0.4029\n",
      "Epoch [1/50Loss D: 0.5570, Loss G: 0.3999\n",
      "Epoch [1/50Loss D: 0.5495, Loss G: 0.4078\n",
      "Epoch [1/50Loss D: 0.5506, Loss G: 0.4059\n",
      "Epoch [1/50Loss D: 0.5471, Loss G: 0.4086\n",
      "Epoch [1/50Loss D: 0.5473, Loss G: 0.4083\n",
      "Epoch [1/50Loss D: 0.5401, Loss G: 0.4152\n",
      "Epoch [1/50Loss D: 0.5455, Loss G: 0.4109\n",
      "Epoch [1/50Loss D: 0.5332, Loss G: 0.4231\n",
      "Epoch [1/50Loss D: 0.4886, Loss G: 0.4739\n",
      "Epoch [1/50Loss D: 0.5890, Loss G: 0.3686\n",
      "Epoch [1/50Loss D: 0.5275, Loss G: 0.4287\n",
      "Epoch [1/50Loss D: 0.5472, Loss G: 0.4081\n",
      "Epoch [1/50Loss D: 0.5601, Loss G: 0.3953\n",
      "Epoch [1/50Loss D: 0.5460, Loss G: 0.4092\n",
      "Epoch [1/50Loss D: 0.5592, Loss G: 0.3966\n",
      "Epoch [1/50Loss D: 0.5317, Loss G: 0.4243\n",
      "Epoch [1/50Loss D: 0.5537, Loss G: 0.4015\n",
      "Epoch [1/50Loss D: 0.5376, Loss G: 0.4177\n",
      "Epoch [1/50Loss D: 0.5552, Loss G: 0.3999\n",
      "Epoch [1/50Loss D: 0.5451, Loss G: 0.4101\n",
      "Epoch [1/50Loss D: 0.5556, Loss G: 0.3995\n",
      "Epoch [1/50Loss D: 0.5454, Loss G: 0.4096\n",
      "Epoch [1/50Loss D: 0.5529, Loss G: 0.4022\n",
      "Epoch [1/50Loss D: 0.5477, Loss G: 0.4072\n",
      "Epoch [1/50Loss D: 0.5529, Loss G: 0.4023\n",
      "Epoch [1/50Loss D: 0.5309, Loss G: 0.4248\n",
      "Epoch [1/50Loss D: 0.5279, Loss G: 0.4280\n",
      "Epoch [1/50Loss D: 0.5459, Loss G: 0.4092\n",
      "Epoch [1/50Loss D: 0.5472, Loss G: 0.4078\n",
      "Epoch [1/50Loss D: 0.5525, Loss G: 0.4026\n",
      "Epoch [1/50Loss D: 0.5190, Loss G: 0.4378\n",
      "Epoch [1/50Loss D: 0.5611, Loss G: 0.3944\n",
      "Epoch [1/50Loss D: 0.5487, Loss G: 0.4065\n",
      "Epoch [1/50Loss D: 0.4997, Loss G: 0.4599\n",
      "Epoch [1/50Loss D: 0.5811, Loss G: 0.3763\n",
      "Epoch [1/50Loss D: 0.6244, Loss G: 0.3394\n",
      "Epoch [1/50Loss D: 0.6176, Loss G: 0.3462\n",
      "Epoch [1/50Loss D: 0.5425, Loss G: 0.4181\n",
      "Epoch [1/50Loss D: 0.5683, Loss G: 0.3891\n",
      "Epoch [1/50Loss D: 0.5577, Loss G: 0.4003\n",
      "Epoch [1/50Loss D: 0.5351, Loss G: 0.4254\n",
      "Epoch [1/50Loss D: 0.6067, Loss G: 0.3650\n",
      "Epoch [1/50Loss D: 0.4948, Loss G: 0.4871\n",
      "Epoch [1/50Loss D: 0.7315, Loss G: 0.2789\n",
      "Epoch [1/50Loss D: 0.6892, Loss G: 0.3040\n",
      "Epoch [1/50Loss D: 0.4300, Loss G: 0.6147\n",
      "Epoch [1/50Loss D: 0.5723, Loss G: 0.4063\n",
      "Epoch [1/50Loss D: 0.5097, Loss G: 0.4686\n",
      "Epoch [1/50Loss D: 0.5552, Loss G: 0.4345\n",
      "Epoch [1/50Loss D: 0.6567, Loss G: 0.3204\n",
      "Epoch [1/50Loss D: 0.5533, Loss G: 0.4043\n",
      "Epoch [1/50Loss D: 0.5466, Loss G: 0.4096\n",
      "Epoch [1/50Loss D: 0.5531, Loss G: 0.4033\n",
      "Epoch [1/50Loss D: 0.5424, Loss G: 0.4151\n",
      "Epoch [1/50Loss D: 0.5281, Loss G: 0.4288\n",
      "Epoch [1/50Loss D: 0.5516, Loss G: 0.4036\n",
      "Epoch [1/50Loss D: 0.5626, Loss G: 0.3931\n",
      "Epoch [1/50Loss D: 0.5355, Loss G: 0.4207\n",
      "Epoch [1/50Loss D: 0.5466, Loss G: 0.4086\n",
      "Epoch [1/50Loss D: 0.5551, Loss G: 0.4002\n",
      "Epoch [1/50Loss D: 0.5478, Loss G: 0.4073\n",
      "Epoch [1/50Loss D: 0.5488, Loss G: 0.4062\n",
      "Epoch [1/50Loss D: 0.5574, Loss G: 0.3978\n",
      "Epoch [1/50Loss D: 0.5478, Loss G: 0.4073\n",
      "Epoch [1/50Loss D: 0.5467, Loss G: 0.4082\n",
      "Epoch [1/50Loss D: 0.5512, Loss G: 0.4037\n",
      "Epoch [1/50Loss D: 0.5426, Loss G: 0.4125\n",
      "Epoch [1/50Loss D: 0.5497, Loss G: 0.4053\n",
      "Epoch [1/50Loss D: 0.5493, Loss G: 0.4058\n",
      "Epoch [1/50Loss D: 0.5499, Loss G: 0.4052\n",
      "Epoch [1/50Loss D: 0.5691, Loss G: 0.3866\n",
      "Epoch [1/50Loss D: 0.5646, Loss G: 0.3918\n",
      "Epoch [1/50Loss D: 0.5243, Loss G: 0.4324\n",
      "Epoch [1/50Loss D: 0.5493, Loss G: 0.4058\n",
      "Epoch [1/50Loss D: 0.5247, Loss G: 0.4314\n",
      "Epoch [1/50Loss D: 0.5516, Loss G: 0.4036\n",
      "Epoch [1/50Loss D: 0.5866, Loss G: 0.3708\n",
      "Epoch [1/50Loss D: 0.5300, Loss G: 0.4274\n",
      "Epoch [1/50Loss D: 0.4439, Loss G: 0.5358\n",
      "Epoch [1/50Loss D: 0.6109, Loss G: 0.3525\n",
      "Epoch [1/50Loss D: 0.5826, Loss G: 0.3774\n",
      "Epoch [1/50Loss D: 0.5096, Loss G: 0.4556\n",
      "Epoch [1/50Loss D: 0.5478, Loss G: 0.4166\n",
      "Epoch [1/50Loss D: 0.6151, Loss G: 0.3530\n",
      "Epoch [1/50Loss D: 0.5860, Loss G: 0.3823\n",
      "Epoch [1/50Loss D: 0.5258, Loss G: 0.4532\n",
      "Epoch [2/50Loss D: 0.5771, Loss G: 0.4042\n",
      "Epoch [2/50Loss D: 0.7490, Loss G: 0.2636\n",
      "Epoch [2/50Loss D: 0.5634, Loss G: 0.4228\n",
      "Epoch [2/50Loss D: 0.6981, Loss G: 0.3071\n",
      "Epoch [2/50Loss D: 0.4584, Loss G: 0.5375\n",
      "Epoch [2/50Loss D: 0.5065, Loss G: 0.4630\n",
      "Epoch [2/50Loss D: 0.4903, Loss G: 0.4786\n",
      "Epoch [2/50Loss D: 0.5459, Loss G: 0.4131\n",
      "Epoch [2/50Loss D: 0.5854, Loss G: 0.3747\n",
      "Epoch [2/50Loss D: 0.5895, Loss G: 0.3711\n",
      "Epoch [2/50Loss D: 0.5257, Loss G: 0.4348\n",
      "Epoch [2/50Loss D: 0.5245, Loss G: 0.4337\n",
      "Epoch [2/50Loss D: 0.5373, Loss G: 0.4192\n",
      "Epoch [2/50Loss D: 0.5500, Loss G: 0.4057\n",
      "Epoch [2/50Loss D: 0.5505, Loss G: 0.4050\n",
      "Epoch [2/50Loss D: 0.5473, Loss G: 0.4085\n",
      "Epoch [2/50Loss D: 0.5623, Loss G: 0.3942\n",
      "Epoch [2/50Loss D: 0.5283, Loss G: 0.4282\n",
      "Epoch [2/50Loss D: 0.5579, Loss G: 0.3978\n",
      "Epoch [2/50Loss D: 0.5450, Loss G: 0.4104\n",
      "Epoch [2/50Loss D: 0.5483, Loss G: 0.4071\n",
      "Epoch [2/50Loss D: 0.5356, Loss G: 0.4208\n",
      "Epoch [2/50Loss D: 0.5523, Loss G: 0.4033\n",
      "Epoch [2/50Loss D: 0.5588, Loss G: 0.3971\n",
      "Epoch [2/50Loss D: 0.5385, Loss G: 0.4172\n",
      "Epoch [2/50Loss D: 0.5585, Loss G: 0.3972\n",
      "Epoch [2/50Loss D: 0.5657, Loss G: 0.3902\n",
      "Epoch [2/50Loss D: 0.5365, Loss G: 0.4192\n",
      "Epoch [2/50Loss D: 0.5462, Loss G: 0.4127\n",
      "Epoch [2/50Loss D: 0.6277, Loss G: 0.3411\n",
      "Epoch [2/50Loss D: 0.5534, Loss G: 0.4134\n",
      "Epoch [2/50Loss D: 0.6180, Loss G: 0.3579\n",
      "Epoch [2/50Loss D: 0.4987, Loss G: 0.4813\n",
      "Epoch [2/50Loss D: 0.8145, Loss G: 0.2414\n",
      "Epoch [2/50Loss D: 0.6605, Loss G: 0.3392\n",
      "Epoch [2/50Loss D: 0.5732, Loss G: 0.4115\n",
      "Epoch [2/50Loss D: 0.5947, Loss G: 0.3824\n",
      "Epoch [2/50Loss D: 0.6241, Loss G: 0.3521\n",
      "Epoch [2/50Loss D: 0.5983, Loss G: 0.3803\n",
      "Epoch [2/50Loss D: 0.5439, Loss G: 0.4139\n",
      "Epoch [2/50Loss D: 0.5789, Loss G: 0.3785\n",
      "Epoch [2/50Loss D: 0.5620, Loss G: 0.3935\n",
      "Epoch [2/50Loss D: 0.5417, Loss G: 0.4141\n",
      "Epoch [2/50Loss D: 0.5449, Loss G: 0.4104\n",
      "Epoch [2/50Loss D: 0.5578, Loss G: 0.3975\n",
      "Epoch [2/50Loss D: 0.5508, Loss G: 0.4042\n",
      "Epoch [2/50Loss D: 0.5480, Loss G: 0.4070\n",
      "Epoch [2/50Loss D: 0.5453, Loss G: 0.4097\n",
      "Epoch [2/50Loss D: 0.5511, Loss G: 0.4039\n",
      "Epoch [2/50Loss D: 0.5506, Loss G: 0.4043\n",
      "Epoch [2/50Loss D: 0.5441, Loss G: 0.4110\n",
      "Epoch [2/50Loss D: 0.5486, Loss G: 0.4063\n",
      "Epoch [2/50Loss D: 0.5486, Loss G: 0.4063\n",
      "Epoch [2/50Loss D: 0.5476, Loss G: 0.4073\n",
      "Epoch [2/50Loss D: 0.5468, Loss G: 0.4082\n",
      "Epoch [2/50Loss D: 0.5436, Loss G: 0.4114\n",
      "Epoch [2/50Loss D: 0.5525, Loss G: 0.4024\n",
      "Epoch [2/50Loss D: 0.5426, Loss G: 0.4124\n",
      "Epoch [2/50Loss D: 0.5386, Loss G: 0.4164\n",
      "Epoch [2/50Loss D: 0.5474, Loss G: 0.4076\n",
      "Epoch [2/50Loss D: 0.5539, Loss G: 0.4011\n",
      "Epoch [2/50Loss D: 0.5597, Loss G: 0.3959\n",
      "Epoch [2/50Loss D: 0.5598, Loss G: 0.3957\n",
      "Epoch [2/50Loss D: 0.5739, Loss G: 0.3820\n",
      "Epoch [2/50Loss D: 0.5723, Loss G: 0.3836\n",
      "Epoch [2/50Loss D: 0.5531, Loss G: 0.4020\n",
      "Epoch [2/50Loss D: 0.5473, Loss G: 0.4085\n",
      "Epoch [2/50Loss D: 0.6277, Loss G: 0.3385\n",
      "Epoch [2/50Loss D: 0.5237, Loss G: 0.4365\n",
      "Epoch [2/50Loss D: 0.5586, Loss G: 0.4032\n",
      "Epoch [2/50Loss D: 0.6250, Loss G: 0.3425\n",
      "Epoch [2/50Loss D: 0.4412, Loss G: 0.5520\n",
      "Epoch [2/50Loss D: 0.4743, Loss G: 0.4977\n",
      "Epoch [2/50Loss D: 0.4799, Loss G: 0.4923\n",
      "Epoch [2/50Loss D: 0.5813, Loss G: 0.4044\n",
      "Epoch [2/50Loss D: 0.5815, Loss G: 0.3928\n",
      "Epoch [2/50Loss D: 0.6080, Loss G: 0.3761\n",
      "Epoch [2/50Loss D: 0.5714, Loss G: 0.4098\n",
      "Epoch [2/50Loss D: 0.5723, Loss G: 0.4061\n",
      "Epoch [2/50Loss D: 0.7163, Loss G: 0.2840\n",
      "Epoch [2/50Loss D: 0.5043, Loss G: 0.5118\n",
      "Epoch [2/50Loss D: 0.5807, Loss G: 0.3913\n",
      "Epoch [2/50Loss D: 0.6113, Loss G: 0.3611\n",
      "Epoch [2/50Loss D: 0.5453, Loss G: 0.4228\n",
      "Epoch [2/50Loss D: 0.6041, Loss G: 0.3723\n",
      "Epoch [2/50Loss D: 0.5815, Loss G: 0.3862\n",
      "Epoch [2/50Loss D: 0.5489, Loss G: 0.4255\n",
      "Epoch [2/50Loss D: 0.6641, Loss G: 0.3183\n",
      "Epoch [2/50Loss D: 0.4523, Loss G: 0.5520\n",
      "Epoch [2/50Loss D: 0.6499, Loss G: 0.3324\n",
      "Epoch [2/50Loss D: 0.5663, Loss G: 0.4058\n",
      "Epoch [2/50Loss D: 0.6844, Loss G: 0.3039\n",
      "Epoch [2/50Loss D: 0.6511, Loss G: 0.3299\n",
      "Epoch [2/50Loss D: 0.6154, Loss G: 0.3645\n",
      "Epoch [2/50Loss D: 0.6355, Loss G: 0.3487\n",
      "Epoch [2/50Loss D: 0.5557, Loss G: 0.4266\n",
      "Epoch [2/50Loss D: 0.6598, Loss G: 0.3299\n",
      "Epoch [2/50Loss D: 0.4624, Loss G: 0.5355\n",
      "Epoch [2/50Loss D: 0.4919, Loss G: 0.4964\n",
      "Epoch [2/50Loss D: 0.6339, Loss G: 0.3449\n",
      "Epoch [2/50Loss D: 0.5730, Loss G: 0.4066\n",
      "Epoch [2/50Loss D: 0.6869, Loss G: 0.3029\n",
      "Epoch [2/50Loss D: 0.6450, Loss G: 0.3444\n",
      "Epoch [2/50Loss D: 0.5380, Loss G: 0.4722\n",
      "Epoch [2/50Loss D: 0.6255, Loss G: 0.3584\n",
      "Epoch [2/50Loss D: 0.5644, Loss G: 0.4266\n",
      "Epoch [2/50Loss D: 0.4812, Loss G: 0.5130\n",
      "Epoch [2/50Loss D: 0.6883, Loss G: 0.3001\n",
      "Epoch [2/50Loss D: 0.8149, Loss G: 0.2324\n",
      "Epoch [2/50Loss D: 0.4680, Loss G: 0.5502\n",
      "Epoch [2/50Loss D: 0.6756, Loss G: 0.3186\n",
      "Epoch [2/50Loss D: 0.6341, Loss G: 0.3511\n",
      "Epoch [2/50Loss D: 0.5943, Loss G: 0.4040\n",
      "Epoch [2/50Loss D: 0.6207, Loss G: 0.3588\n",
      "Epoch [2/50Loss D: 0.5901, Loss G: 0.3976\n",
      "Epoch [2/50Loss D: 0.5044, Loss G: 0.4867\n",
      "Epoch [2/50Loss D: 0.5332, Loss G: 0.4481\n",
      "Epoch [2/50Loss D: 0.5010, Loss G: 0.4962\n",
      "Epoch [2/50Loss D: 0.6675, Loss G: 0.3211\n",
      "Epoch [2/50Loss D: 0.5517, Loss G: 0.4260\n",
      "Epoch [2/50Loss D: 0.5005, Loss G: 0.4808\n",
      "Epoch [2/50Loss D: 0.6971, Loss G: 0.2946\n",
      "Epoch [2/50Loss D: 0.5664, Loss G: 0.3999\n",
      "Epoch [2/50Loss D: 0.4791, Loss G: 0.5102\n",
      "Epoch [2/50Loss D: 0.7107, Loss G: 0.2974\n",
      "Epoch [2/50Loss D: 0.6803, Loss G: 0.3258\n",
      "Epoch [2/50Loss D: 0.5929, Loss G: 0.4040\n",
      "Epoch [2/50Loss D: 0.5563, Loss G: 0.4479\n",
      "Epoch [2/50Loss D: 0.6304, Loss G: 0.3669\n",
      "Epoch [2/50Loss D: 0.5821, Loss G: 0.4071\n",
      "Epoch [2/50Loss D: 0.7291, Loss G: 0.2775\n",
      "Epoch [2/50Loss D: 0.5597, Loss G: 0.4150\n",
      "Epoch [2/50Loss D: 0.4531, Loss G: 0.5609\n",
      "Epoch [2/50Loss D: 0.6399, Loss G: 0.3452\n",
      "Epoch [2/50Loss D: 0.5916, Loss G: 0.3945\n",
      "Epoch [2/50Loss D: 0.5090, Loss G: 0.4727\n",
      "Epoch [2/50Loss D: 0.5423, Loss G: 0.4427\n",
      "Epoch [2/50Loss D: 0.7023, Loss G: 0.3029\n",
      "Epoch [2/50Loss D: 0.5726, Loss G: 0.4086\n",
      "Epoch [2/50Loss D: 0.5957, Loss G: 0.3811\n",
      "Epoch [2/50Loss D: 0.6145, Loss G: 0.3668\n",
      "Epoch [2/50Loss D: 0.6384, Loss G: 0.3542\n",
      "Epoch [2/50Loss D: 0.7184, Loss G: 0.2908\n",
      "Epoch [2/50Loss D: 0.6005, Loss G: 0.3872\n",
      "Epoch [2/50Loss D: 0.5269, Loss G: 0.4614\n",
      "Epoch [2/50Loss D: 0.7126, Loss G: 0.2898\n",
      "Epoch [2/50Loss D: 0.6862, Loss G: 0.3352\n",
      "Epoch [2/50Loss D: 0.8132, Loss G: 0.2362\n",
      "Epoch [2/50Loss D: 0.5057, Loss G: 0.4876\n",
      "Epoch [2/50Loss D: 0.7419, Loss G: 0.2773\n",
      "Epoch [2/50Loss D: 0.6120, Loss G: 0.3715\n",
      "Epoch [2/50Loss D: 0.5561, Loss G: 0.4362\n",
      "Epoch [2/50Loss D: 0.7077, Loss G: 0.2911\n",
      "Epoch [2/50Loss D: 0.5788, Loss G: 0.4091\n",
      "Epoch [2/50Loss D: 0.5790, Loss G: 0.4002\n",
      "Epoch [2/50Loss D: 0.5920, Loss G: 0.3867\n",
      "Epoch [2/50Loss D: 0.4904, Loss G: 0.4932\n",
      "Epoch [2/50Loss D: 0.5937, Loss G: 0.3859\n",
      "Epoch [2/50Loss D: 0.5838, Loss G: 0.4056\n",
      "Epoch [2/50Loss D: 0.6581, Loss G: 0.3418\n",
      "Epoch [2/50Loss D: 0.7121, Loss G: 0.2981\n",
      "Epoch [2/50Loss D: 0.6317, Loss G: 0.3601\n",
      "Epoch [2/50Loss D: 0.6722, Loss G: 0.3193\n",
      "Epoch [2/50Loss D: 0.6414, Loss G: 0.3530\n",
      "Epoch [2/50Loss D: 0.6931, Loss G: 0.3135\n",
      "Epoch [2/50Loss D: 0.6594, Loss G: 0.3370\n",
      "Epoch [2/50Loss D: 0.6505, Loss G: 0.3693\n",
      "Epoch [2/50Loss D: 0.7820, Loss G: 0.2658\n",
      "Epoch [2/50Loss D: 0.8343, Loss G: 0.2355\n",
      "Epoch [2/50Loss D: 0.6596, Loss G: 0.3441\n",
      "Epoch [2/50Loss D: 0.6899, Loss G: 0.3316\n",
      "Epoch [2/50Loss D: 0.6623, Loss G: 0.3930\n",
      "Epoch [2/50Loss D: 0.4946, Loss G: 0.5028\n",
      "Epoch [2/50Loss D: 0.6470, Loss G: 0.3345\n",
      "Epoch [2/50Loss D: 0.7600, Loss G: 0.2640\n",
      "Epoch [2/50Loss D: 0.5287, Loss G: 0.4729\n",
      "Epoch [2/50Loss D: 0.5727, Loss G: 0.4090\n",
      "Epoch [2/50Loss D: 0.5377, Loss G: 0.4548\n",
      "Epoch [2/50Loss D: 0.6274, Loss G: 0.3557\n",
      "Epoch [2/50Loss D: 0.6876, Loss G: 0.3118\n",
      "Epoch [2/50Loss D: 0.8805, Loss G: 0.2115\n",
      "Epoch [2/50Loss D: 0.6751, Loss G: 0.3559\n",
      "Epoch [2/50Loss D: 0.6670, Loss G: 0.3304\n",
      "Epoch [2/50Loss D: 0.4915, Loss G: 0.5198\n",
      "Epoch [2/50Loss D: 0.6290, Loss G: 0.3677\n",
      "Epoch [2/50Loss D: 0.6767, Loss G: 0.3236\n",
      "Epoch [2/50Loss D: 0.6098, Loss G: 0.3911\n",
      "Epoch [2/50Loss D: 0.4988, Loss G: 0.5271\n",
      "Epoch [3/50Loss D: 0.4696, Loss G: 0.6242\n",
      "Epoch [3/50Loss D: 0.7359, Loss G: 0.2851\n",
      "Epoch [3/50Loss D: 0.6936, Loss G: 0.3292\n",
      "Epoch [3/50Loss D: 0.7731, Loss G: 0.2870\n",
      "Epoch [3/50Loss D: 0.6637, Loss G: 0.3434\n",
      "Epoch [3/50Loss D: 0.6540, Loss G: 0.3476\n",
      "Epoch [3/50Loss D: 0.5854, Loss G: 0.4097\n",
      "Epoch [3/50Loss D: 0.6745, Loss G: 0.3416\n",
      "Epoch [3/50Loss D: 0.7267, Loss G: 0.3330\n",
      "Epoch [3/50Loss D: 0.7148, Loss G: 0.3282\n",
      "Epoch [3/50Loss D: 0.5121, Loss G: 0.5261\n",
      "Epoch [3/50Loss D: 0.7875, Loss G: 0.2543\n",
      "Epoch [3/50Loss D: 0.5479, Loss G: 0.4712\n",
      "Epoch [3/50Loss D: 0.7176, Loss G: 0.2956\n",
      "Epoch [3/50Loss D: 0.5979, Loss G: 0.3983\n",
      "Epoch [3/50Loss D: 0.7113, Loss G: 0.3004\n",
      "Epoch [3/50Loss D: 0.5472, Loss G: 0.4788\n",
      "Epoch [3/50Loss D: 0.6691, Loss G: 0.3493\n",
      "Epoch [3/50Loss D: 0.7472, Loss G: 0.2973\n",
      "Epoch [3/50Loss D: 0.6172, Loss G: 0.4241\n",
      "Epoch [3/50Loss D: 0.6090, Loss G: 0.4152\n",
      "Epoch [3/50Loss D: 0.7513, Loss G: 0.2875\n",
      "Epoch [3/50Loss D: 0.5913, Loss G: 0.4302\n",
      "Epoch [3/50Loss D: 0.6894, Loss G: 0.3231\n",
      "Epoch [3/50Loss D: 0.6806, Loss G: 0.3696\n",
      "Epoch [3/50Loss D: 0.7233, Loss G: 0.3087\n",
      "Epoch [3/50Loss D: 0.6534, Loss G: 0.3847\n",
      "Epoch [3/50Loss D: 0.5650, Loss G: 0.4564\n",
      "Epoch [3/50Loss D: 0.6341, Loss G: 0.3641\n",
      "Epoch [3/50Loss D: 0.6222, Loss G: 0.3738\n",
      "Epoch [3/50Loss D: 0.5088, Loss G: 0.5239\n",
      "Epoch [3/50Loss D: 0.6739, Loss G: 0.3709\n",
      "Epoch [3/50Loss D: 0.8545, Loss G: 0.2327\n",
      "Epoch [3/50Loss D: 0.6138, Loss G: 0.4012\n",
      "Epoch [3/50Loss D: 0.5700, Loss G: 0.4188\n",
      "Epoch [3/50Loss D: 0.6831, Loss G: 0.3237\n",
      "Epoch [3/50Loss D: 0.5451, Loss G: 0.4683\n",
      "Epoch [3/50Loss D: 0.8371, Loss G: 0.2209\n",
      "Epoch [3/50Loss D: 0.5424, Loss G: 0.5117\n",
      "Epoch [3/50Loss D: 0.6865, Loss G: 0.3677\n",
      "Epoch [3/50Loss D: 0.7395, Loss G: 0.3097\n",
      "Epoch [3/50Loss D: 0.7632, Loss G: 0.2871\n",
      "Epoch [3/50Loss D: 0.7948, Loss G: 0.2581\n",
      "Epoch [3/50Loss D: 0.6296, Loss G: 0.3962\n",
      "Epoch [3/50Loss D: 0.6410, Loss G: 0.3945\n",
      "Epoch [3/50Loss D: 0.7404, Loss G: 0.2837\n",
      "Epoch [3/50Loss D: 0.7734, Loss G: 0.2821\n",
      "Epoch [3/50Loss D: 0.6557, Loss G: 0.4227\n",
      "Epoch [3/50Loss D: 0.6781, Loss G: 0.3595\n",
      "Epoch [3/50Loss D: 0.6598, Loss G: 0.3730\n",
      "Epoch [3/50Loss D: 0.6880, Loss G: 0.3398\n",
      "Epoch [3/50Loss D: 0.7006, Loss G: 0.3126\n",
      "Epoch [3/50Loss D: 0.7174, Loss G: 0.3299\n",
      "Epoch [3/50Loss D: 0.5975, Loss G: 0.4460\n",
      "Epoch [3/50Loss D: 0.7977, Loss G: 0.2548\n",
      "Epoch [3/50Loss D: 0.6014, Loss G: 0.4196\n",
      "Epoch [3/50Loss D: 0.6500, Loss G: 0.3668\n",
      "Epoch [3/50Loss D: 0.5954, Loss G: 0.4233\n",
      "Epoch [3/50Loss D: 0.8259, Loss G: 0.2348\n",
      "Epoch [3/50Loss D: 0.5436, Loss G: 0.4868\n",
      "Epoch [3/50Loss D: 0.8936, Loss G: 0.2098\n",
      "Epoch [3/50Loss D: 0.5620, Loss G: 0.4885\n",
      "Epoch [3/50Loss D: 0.5395, Loss G: 0.4692\n",
      "Epoch [3/50Loss D: 0.7386, Loss G: 0.2890\n",
      "Epoch [3/50Loss D: 0.6433, Loss G: 0.4194\n",
      "Epoch [3/50Loss D: 0.6945, Loss G: 0.3255\n",
      "Epoch [3/50Loss D: 0.5474, Loss G: 0.4551\n",
      "Epoch [3/50Loss D: 0.7988, Loss G: 0.2698\n",
      "Epoch [3/50Loss D: 0.6842, Loss G: 0.3792\n",
      "Epoch [3/50Loss D: 0.7336, Loss G: 0.3142\n",
      "Epoch [3/50Loss D: 0.5393, Loss G: 0.4638\n",
      "Epoch [3/50Loss D: 0.6731, Loss G: 0.3434\n",
      "Epoch [3/50Loss D: 0.6421, Loss G: 0.4133\n",
      "Epoch [3/50Loss D: 0.6226, Loss G: 0.4063\n",
      "Epoch [3/50Loss D: 0.6842, Loss G: 0.3765\n",
      "Epoch [3/50Loss D: 0.5411, Loss G: 0.5183\n",
      "Epoch [3/50Loss D: 0.8645, Loss G: 0.2167\n",
      "Epoch [3/50Loss D: 0.6205, Loss G: 0.3981\n",
      "Epoch [3/50Loss D: 0.6473, Loss G: 0.3621\n",
      "Epoch [3/50Loss D: 0.5340, Loss G: 0.5061\n",
      "Epoch [3/50Loss D: 0.7180, Loss G: 0.3186\n",
      "Epoch [3/50Loss D: 0.7086, Loss G: 0.3465\n",
      "Epoch [3/50Loss D: 0.6329, Loss G: 0.3826\n",
      "Epoch [3/50Loss D: 0.6981, Loss G: 0.3301\n",
      "Epoch [3/50Loss D: 0.6217, Loss G: 0.4229\n",
      "Epoch [3/50Loss D: 0.5750, Loss G: 0.4570\n",
      "Epoch [3/50Loss D: 0.5733, Loss G: 0.4371\n",
      "Epoch [3/50Loss D: 0.9221, Loss G: 0.2012\n",
      "Epoch [3/50Loss D: 0.6795, Loss G: 0.3926\n",
      "Epoch [3/50Loss D: 0.8218, Loss G: 0.2415\n",
      "Epoch [3/50Loss D: 0.6835, Loss G: 0.3361\n",
      "Epoch [3/50Loss D: 0.5598, Loss G: 0.4882\n",
      "Epoch [3/50Loss D: 0.7244, Loss G: 0.3085\n",
      "Epoch [3/50Loss D: 0.6239, Loss G: 0.4212\n",
      "Epoch [3/50Loss D: 0.8054, Loss G: 0.2785\n",
      "Epoch [3/50Loss D: 0.8498, Loss G: 0.2357\n",
      "Epoch [3/50Loss D: 0.7730, Loss G: 0.2790\n",
      "Epoch [3/50Loss D: 0.6065, Loss G: 0.3990\n",
      "Epoch [3/50Loss D: 0.6362, Loss G: 0.3977\n",
      "Epoch [3/50Loss D: 0.6230, Loss G: 0.3990\n",
      "Epoch [3/50Loss D: 0.6906, Loss G: 0.3287\n",
      "Epoch [3/50Loss D: 0.6912, Loss G: 0.3520\n",
      "Epoch [3/50Loss D: 0.7193, Loss G: 0.3550\n",
      "Epoch [3/50Loss D: 0.7633, Loss G: 0.3099\n",
      "Epoch [3/50Loss D: 0.6661, Loss G: 0.3576\n",
      "Epoch [3/50Loss D: 0.5101, Loss G: 0.5307\n",
      "Epoch [3/50Loss D: 0.7451, Loss G: 0.2931\n",
      "Epoch [3/50Loss D: 0.5731, Loss G: 0.4931\n",
      "Epoch [3/50Loss D: 0.7928, Loss G: 0.2628\n",
      "Epoch [3/50Loss D: 0.6209, Loss G: 0.4496\n",
      "Epoch [3/50Loss D: 0.7769, Loss G: 0.2823\n",
      "Epoch [3/50Loss D: 0.5669, Loss G: 0.4789\n",
      "Epoch [3/50Loss D: 0.7067, Loss G: 0.3154\n",
      "Epoch [3/50Loss D: 0.7454, Loss G: 0.2921\n",
      "Epoch [3/50Loss D: 0.5272, Loss G: 0.4911\n",
      "Epoch [3/50Loss D: 0.6588, Loss G: 0.3940\n",
      "Epoch [3/50Loss D: 0.6128, Loss G: 0.4506\n",
      "Epoch [3/50Loss D: 0.7121, Loss G: 0.3273\n",
      "Epoch [3/50Loss D: 0.7146, Loss G: 0.3194\n",
      "Epoch [3/50Loss D: 0.6235, Loss G: 0.3970\n",
      "Epoch [3/50Loss D: 0.7699, Loss G: 0.2937\n",
      "Epoch [3/50Loss D: 0.6704, Loss G: 0.3757\n",
      "Epoch [3/50Loss D: 0.7186, Loss G: 0.3260\n",
      "Epoch [3/50Loss D: 0.6157, Loss G: 0.4198\n",
      "Epoch [3/50Loss D: 0.7539, Loss G: 0.2835\n",
      "Epoch [3/50Loss D: 0.6251, Loss G: 0.4574\n",
      "Epoch [3/50Loss D: 0.6945, Loss G: 0.3524\n",
      "Epoch [3/50Loss D: 0.5456, Loss G: 0.5150\n",
      "Epoch [3/50Loss D: 0.6387, Loss G: 0.4065\n",
      "Epoch [3/50Loss D: 0.7365, Loss G: 0.3061\n",
      "Epoch [3/50Loss D: 0.6628, Loss G: 0.3741\n",
      "Epoch [3/50Loss D: 0.7415, Loss G: 0.2836\n",
      "Epoch [3/50Loss D: 0.6109, Loss G: 0.4265\n",
      "Epoch [3/50Loss D: 0.7978, Loss G: 0.2536\n",
      "Epoch [3/50Loss D: 0.5591, Loss G: 0.4721\n",
      "Epoch [3/50Loss D: 0.7316, Loss G: 0.3242\n",
      "Epoch [3/50Loss D: 0.7390, Loss G: 0.3386\n",
      "Epoch [3/50Loss D: 0.6782, Loss G: 0.3681\n",
      "Epoch [3/50Loss D: 0.6616, Loss G: 0.4135\n",
      "Epoch [3/50Loss D: 0.7263, Loss G: 0.3176\n",
      "Epoch [3/50Loss D: 0.6035, Loss G: 0.4357\n",
      "Epoch [3/50Loss D: 0.6202, Loss G: 0.3985\n",
      "Epoch [3/50Loss D: 0.7651, Loss G: 0.2848\n",
      "Epoch [3/50Loss D: 0.6115, Loss G: 0.4352\n",
      "Epoch [3/50Loss D: 0.7777, Loss G: 0.2749\n",
      "Epoch [3/50Loss D: 0.6366, Loss G: 0.4096\n",
      "Epoch [3/50Loss D: 0.8230, Loss G: 0.2432\n",
      "Epoch [3/50Loss D: 0.6002, Loss G: 0.4665\n",
      "Epoch [3/50Loss D: 0.8829, Loss G: 0.2302\n",
      "Epoch [3/50Loss D: 0.7481, Loss G: 0.3049\n",
      "Epoch [3/50Loss D: 0.7692, Loss G: 0.2769\n",
      "Epoch [3/50Loss D: 0.6865, Loss G: 0.3807\n",
      "Epoch [3/50Loss D: 0.6429, Loss G: 0.3816\n",
      "Epoch [3/50Loss D: 0.7211, Loss G: 0.3280\n",
      "Epoch [3/50Loss D: 0.7906, Loss G: 0.2652\n",
      "Epoch [3/50Loss D: 0.5987, Loss G: 0.4456\n",
      "Epoch [3/50Loss D: 0.7861, Loss G: 0.2784\n",
      "Epoch [3/50Loss D: 0.6573, Loss G: 0.4009\n",
      "Epoch [3/50Loss D: 0.6451, Loss G: 0.3987\n",
      "Epoch [3/50Loss D: 0.7360, Loss G: 0.3031\n",
      "Epoch [3/50Loss D: 0.6409, Loss G: 0.3809\n",
      "Epoch [3/50Loss D: 0.7321, Loss G: 0.3032\n",
      "Epoch [3/50Loss D: 0.5370, Loss G: 0.4926\n",
      "Epoch [3/50Loss D: 0.7335, Loss G: 0.3109\n",
      "Epoch [3/50Loss D: 0.6848, Loss G: 0.4018\n",
      "Epoch [3/50Loss D: 0.8637, Loss G: 0.2192\n",
      "Epoch [3/50Loss D: 0.7180, Loss G: 0.3221\n",
      "Epoch [3/50Loss D: 0.7220, Loss G: 0.3193\n",
      "Epoch [3/50Loss D: 0.7050, Loss G: 0.3502\n",
      "Epoch [3/50Loss D: 0.7281, Loss G: 0.3513\n",
      "Epoch [3/50Loss D: 0.8208, Loss G: 0.2549\n",
      "Epoch [3/50Loss D: 0.6137, Loss G: 0.4310\n",
      "Epoch [3/50Loss D: 0.8270, Loss G: 0.2540\n",
      "Epoch [3/50Loss D: 0.5196, Loss G: 0.5268\n",
      "Epoch [3/50Loss D: 0.7034, Loss G: 0.3315\n",
      "Epoch [3/50Loss D: 0.8221, Loss G: 0.2741\n",
      "Epoch [3/50Loss D: 0.7559, Loss G: 0.2866\n",
      "Epoch [3/50Loss D: 0.6935, Loss G: 0.3752\n",
      "Epoch [3/50Loss D: 0.6410, Loss G: 0.4079\n",
      "Epoch [3/50Loss D: 0.7588, Loss G: 0.3036\n",
      "Epoch [3/50Loss D: 0.5889, Loss G: 0.4423\n",
      "Epoch [3/50Loss D: 0.6686, Loss G: 0.3688\n",
      "Epoch [3/50Loss D: 0.6098, Loss G: 0.4430\n",
      "Epoch [3/50Loss D: 0.5971, Loss G: 0.4567\n",
      "Epoch [3/50Loss D: 0.6884, Loss G: 0.3983\n",
      "Epoch [3/50Loss D: 0.7285, Loss G: 0.3192\n",
      "Epoch [3/50Loss D: 0.7574, Loss G: 0.2942\n",
      "Epoch [3/50Loss D: 0.7422, Loss G: 0.3086\n",
      "Epoch [4/50Loss D: 0.7131, Loss G: 0.3516\n",
      "Epoch [4/50Loss D: 0.8529, Loss G: 0.2417\n",
      "Epoch [4/50Loss D: 0.6626, Loss G: 0.4131\n",
      "Epoch [4/50Loss D: 0.6813, Loss G: 0.3896\n",
      "Epoch [4/50Loss D: 0.8418, Loss G: 0.2572\n",
      "Epoch [4/50Loss D: 0.6186, Loss G: 0.4022\n",
      "Epoch [4/50Loss D: 0.6220, Loss G: 0.4216\n",
      "Epoch [4/50Loss D: 0.6475, Loss G: 0.4506\n",
      "Epoch [4/50Loss D: 0.8345, Loss G: 0.2575\n",
      "Epoch [4/50Loss D: 0.7632, Loss G: 0.3115\n",
      "Epoch [4/50Loss D: 0.7509, Loss G: 0.3147\n",
      "Epoch [4/50Loss D: 0.6238, Loss G: 0.4161\n",
      "Epoch [4/50Loss D: 0.7315, Loss G: 0.3321\n",
      "Epoch [4/50Loss D: 0.6931, Loss G: 0.3609\n",
      "Epoch [4/50Loss D: 0.8533, Loss G: 0.2486\n",
      "Epoch [4/50Loss D: 0.6327, Loss G: 0.4246\n",
      "Epoch [4/50Loss D: 0.6749, Loss G: 0.3884\n",
      "Epoch [4/50Loss D: 0.8266, Loss G: 0.2591\n",
      "Epoch [4/50Loss D: 0.6193, Loss G: 0.4198\n",
      "Epoch [4/50Loss D: 0.7389, Loss G: 0.3423\n",
      "Epoch [4/50Loss D: 0.7231, Loss G: 0.3370\n",
      "Epoch [4/50Loss D: 0.6896, Loss G: 0.3584\n",
      "Epoch [4/50Loss D: 0.6664, Loss G: 0.3441\n",
      "Epoch [4/50Loss D: 0.6378, Loss G: 0.4041\n",
      "Epoch [4/50Loss D: 0.6502, Loss G: 0.3944\n",
      "Epoch [4/50Loss D: 0.8909, Loss G: 0.2295\n",
      "Epoch [4/50Loss D: 0.6721, Loss G: 0.3937\n",
      "Epoch [4/50Loss D: 0.7987, Loss G: 0.2701\n",
      "Epoch [4/50Loss D: 0.5713, Loss G: 0.4793\n",
      "Epoch [4/50Loss D: 0.7657, Loss G: 0.2909\n",
      "Epoch [4/50Loss D: 0.6083, Loss G: 0.5258\n",
      "Epoch [4/50Loss D: 0.8331, Loss G: 0.2466\n",
      "Epoch [4/50Loss D: 0.8039, Loss G: 0.2575\n",
      "Epoch [4/50Loss D: 0.6565, Loss G: 0.4215\n",
      "Epoch [4/50Loss D: 0.6295, Loss G: 0.4290\n",
      "Epoch [4/50Loss D: 0.6628, Loss G: 0.3711\n",
      "Epoch [4/50Loss D: 0.7520, Loss G: 0.3026\n",
      "Epoch [4/50Loss D: 0.6543, Loss G: 0.4294\n",
      "Epoch [4/50Loss D: 0.7216, Loss G: 0.3351\n",
      "Epoch [4/50Loss D: 0.7764, Loss G: 0.2841\n",
      "Epoch [4/50Loss D: 0.7612, Loss G: 0.2819\n",
      "Epoch [4/50Loss D: 0.6247, Loss G: 0.4097\n",
      "Epoch [4/50Loss D: 0.7468, Loss G: 0.3096\n",
      "Epoch [4/50Loss D: 0.7026, Loss G: 0.3552\n",
      "Epoch [4/50Loss D: 0.8078, Loss G: 0.2770\n",
      "Epoch [4/50Loss D: 0.6486, Loss G: 0.4410\n",
      "Epoch [4/50Loss D: 0.7549, Loss G: 0.3023\n",
      "Epoch [4/50Loss D: 0.6384, Loss G: 0.3872\n",
      "Epoch [4/50Loss D: 0.6031, Loss G: 0.4502\n",
      "Epoch [4/50Loss D: 0.7256, Loss G: 0.3112\n",
      "Epoch [4/50Loss D: 0.7565, Loss G: 0.3151\n",
      "Epoch [4/50Loss D: 0.5456, Loss G: 0.5387\n",
      "Epoch [4/50Loss D: 0.8635, Loss G: 0.2322\n",
      "Epoch [4/50Loss D: 0.7403, Loss G: 0.3273\n",
      "Epoch [4/50Loss D: 0.6544, Loss G: 0.3833\n",
      "Epoch [4/50Loss D: 0.6644, Loss G: 0.3851\n",
      "Epoch [4/50Loss D: 0.6513, Loss G: 0.3805\n",
      "Epoch [4/50Loss D: 0.7367, Loss G: 0.3027\n",
      "Epoch [4/50Loss D: 0.7795, Loss G: 0.2792\n",
      "Epoch [4/50Loss D: 0.7651, Loss G: 0.2940\n",
      "Epoch [4/50Loss D: 0.7250, Loss G: 0.3182\n",
      "Epoch [4/50Loss D: 0.6508, Loss G: 0.3912\n",
      "Epoch [4/50Loss D: 0.7361, Loss G: 0.3325\n",
      "Epoch [4/50Loss D: 0.6890, Loss G: 0.3566\n",
      "Epoch [4/50Loss D: 0.6517, Loss G: 0.3846\n",
      "Epoch [4/50Loss D: 0.6507, Loss G: 0.3960\n",
      "Epoch [4/50Loss D: 0.8632, Loss G: 0.2325\n",
      "Epoch [4/50Loss D: 0.7080, Loss G: 0.3321\n",
      "Epoch [4/50Loss D: 0.6548, Loss G: 0.3985\n",
      "Epoch [4/50Loss D: 0.8243, Loss G: 0.2631\n",
      "Epoch [4/50Loss D: 0.7603, Loss G: 0.3019\n",
      "Epoch [4/50Loss D: 0.7598, Loss G: 0.3332\n",
      "Epoch [4/50Loss D: 0.8036, Loss G: 0.2742\n",
      "Epoch [4/50Loss D: 0.7448, Loss G: 0.3219\n",
      "Epoch [4/50Loss D: 0.7707, Loss G: 0.2950\n",
      "Epoch [4/50Loss D: 0.6052, Loss G: 0.4359\n",
      "Epoch [4/50Loss D: 0.7649, Loss G: 0.2922\n",
      "Epoch [4/50Loss D: 0.6953, Loss G: 0.3626\n",
      "Epoch [4/50Loss D: 0.7048, Loss G: 0.3505\n",
      "Epoch [4/50Loss D: 0.7810, Loss G: 0.2926\n",
      "Epoch [4/50Loss D: 0.6801, Loss G: 0.3608\n",
      "Epoch [4/50Loss D: 0.6121, Loss G: 0.4231\n",
      "Epoch [4/50Loss D: 0.6852, Loss G: 0.3782\n",
      "Epoch [4/50Loss D: 0.7401, Loss G: 0.3254\n",
      "Epoch [4/50Loss D: 0.7720, Loss G: 0.2922\n",
      "Epoch [4/50Loss D: 0.6752, Loss G: 0.3914\n",
      "Epoch [4/50Loss D: 0.8190, Loss G: 0.2704\n",
      "Epoch [4/50Loss D: 0.5288, Loss G: 0.6336\n",
      "Epoch [4/50Loss D: 0.8112, Loss G: 0.2497\n",
      "Epoch [4/50Loss D: 0.6872, Loss G: 0.3686\n",
      "Epoch [4/50Loss D: 0.6472, Loss G: 0.3812\n",
      "Epoch [4/50Loss D: 0.8048, Loss G: 0.2787\n",
      "Epoch [4/50Loss D: 0.6728, Loss G: 0.3760\n",
      "Epoch [4/50Loss D: 0.6941, Loss G: 0.3506\n",
      "Epoch [4/50Loss D: 0.7829, Loss G: 0.2861\n",
      "Epoch [4/50Loss D: 0.7197, Loss G: 0.3273\n",
      "Epoch [4/50Loss D: 0.5794, Loss G: 0.5265\n",
      "Epoch [4/50Loss D: 0.6680, Loss G: 0.4111\n",
      "Epoch [4/50Loss D: 0.7463, Loss G: 0.3259\n",
      "Epoch [4/50Loss D: 0.6171, Loss G: 0.4496\n",
      "Epoch [4/50Loss D: 0.7137, Loss G: 0.3248\n",
      "Epoch [4/50Loss D: 0.6804, Loss G: 0.3725\n",
      "Epoch [4/50Loss D: 0.7568, Loss G: 0.3026\n",
      "Epoch [4/50Loss D: 0.7509, Loss G: 0.3192\n",
      "Epoch [4/50Loss D: 0.7216, Loss G: 0.3367\n",
      "Epoch [4/50Loss D: 0.6758, Loss G: 0.4079\n",
      "Epoch [4/50Loss D: 0.7289, Loss G: 0.3132\n",
      "Epoch [4/50Loss D: 0.6721, Loss G: 0.4134\n",
      "Epoch [4/50Loss D: 0.6909, Loss G: 0.3514\n",
      "Epoch [4/50Loss D: 0.7398, Loss G: 0.3129\n",
      "Epoch [4/50Loss D: 0.7017, Loss G: 0.3484\n",
      "Epoch [4/50Loss D: 0.7075, Loss G: 0.3615\n",
      "Epoch [4/50Loss D: 0.6823, Loss G: 0.3757\n",
      "Epoch [4/50Loss D: 0.7036, Loss G: 0.3476\n",
      "Epoch [4/50Loss D: 0.8159, Loss G: 0.2538\n",
      "Epoch [4/50Loss D: 0.5957, Loss G: 0.4724\n",
      "Epoch [4/50Loss D: 0.7266, Loss G: 0.3029\n",
      "Epoch [4/50Loss D: 0.6947, Loss G: 0.3462\n",
      "Epoch [4/50Loss D: 0.7255, Loss G: 0.3694\n",
      "Epoch [4/50Loss D: 0.7773, Loss G: 0.2876\n",
      "Epoch [4/50Loss D: 0.7165, Loss G: 0.3417\n",
      "Epoch [4/50Loss D: 0.6815, Loss G: 0.3556\n",
      "Epoch [4/50Loss D: 0.7370, Loss G: 0.3073\n",
      "Epoch [4/50Loss D: 0.6429, Loss G: 0.4165\n",
      "Epoch [4/50Loss D: 0.8047, Loss G: 0.2617\n",
      "Epoch [4/50Loss D: 0.5818, Loss G: 0.4836\n",
      "Epoch [4/50Loss D: 0.7226, Loss G: 0.3196\n",
      "Epoch [4/50Loss D: 0.6724, Loss G: 0.3813\n",
      "Epoch [4/50Loss D: 0.7998, Loss G: 0.2743\n",
      "Epoch [4/50Loss D: 0.6903, Loss G: 0.3878\n",
      "Epoch [4/50Loss D: 0.6934, Loss G: 0.3341\n",
      "Epoch [4/50Loss D: 0.7095, Loss G: 0.3256\n",
      "Epoch [4/50Loss D: 0.7186, Loss G: 0.3559\n",
      "Epoch [4/50Loss D: 0.6922, Loss G: 0.3582\n",
      "Epoch [4/50Loss D: 0.7541, Loss G: 0.3043\n",
      "Epoch [4/50Loss D: 0.7186, Loss G: 0.3448\n",
      "Epoch [4/50Loss D: 0.8840, Loss G: 0.2356\n",
      "Epoch [4/50Loss D: 0.7317, Loss G: 0.3195\n",
      "Epoch [4/50Loss D: 0.6271, Loss G: 0.4226\n",
      "Epoch [4/50Loss D: 0.6255, Loss G: 0.4316\n",
      "Epoch [4/50Loss D: 0.7833, Loss G: 0.2688\n",
      "Epoch [4/50Loss D: 0.7875, Loss G: 0.2847\n",
      "Epoch [4/50Loss D: 0.8017, Loss G: 0.2763\n",
      "Epoch [4/50Loss D: 0.7500, Loss G: 0.3422\n",
      "Epoch [4/50Loss D: 0.5961, Loss G: 0.4654\n",
      "Epoch [4/50Loss D: 0.7703, Loss G: 0.2964\n",
      "Epoch [4/50Loss D: 0.7294, Loss G: 0.3250\n",
      "Epoch [4/50Loss D: 0.6859, Loss G: 0.3774\n",
      "Epoch [4/50Loss D: 0.7500, Loss G: 0.3446\n",
      "Epoch [4/50Loss D: 0.7547, Loss G: 0.3039\n",
      "Epoch [4/50Loss D: 0.8774, Loss G: 0.2328\n",
      "Epoch [4/50Loss D: 0.6795, Loss G: 0.3792\n",
      "Epoch [4/50Loss D: 0.7738, Loss G: 0.3133\n",
      "Epoch [4/50Loss D: 0.7284, Loss G: 0.3186\n",
      "Epoch [4/50Loss D: 0.6645, Loss G: 0.3729\n",
      "Epoch [4/50Loss D: 0.6838, Loss G: 0.3543\n",
      "Epoch [4/50Loss D: 0.7328, Loss G: 0.3271\n",
      "Epoch [4/50Loss D: 0.6968, Loss G: 0.3461\n",
      "Epoch [4/50Loss D: 0.7381, Loss G: 0.3073\n",
      "Epoch [4/50Loss D: 0.6316, Loss G: 0.4175\n",
      "Epoch [4/50Loss D: 0.8515, Loss G: 0.2487\n",
      "Epoch [4/50Loss D: 0.5921, Loss G: 0.4941\n",
      "Epoch [4/50Loss D: 0.7416, Loss G: 0.3225\n",
      "Epoch [4/50Loss D: 0.7074, Loss G: 0.3455\n",
      "Epoch [4/50Loss D: 0.8456, Loss G: 0.2534\n",
      "Epoch [4/50Loss D: 0.6943, Loss G: 0.3548\n",
      "Epoch [4/50Loss D: 0.7155, Loss G: 0.3600\n",
      "Epoch [4/50Loss D: 0.6424, Loss G: 0.4330\n",
      "Epoch [4/50Loss D: 0.7718, Loss G: 0.2849\n",
      "Epoch [4/50Loss D: 0.7480, Loss G: 0.2947\n",
      "Epoch [4/50Loss D: 0.6704, Loss G: 0.4149\n",
      "Epoch [4/50Loss D: 0.7760, Loss G: 0.2883\n",
      "Epoch [4/50Loss D: 0.7103, Loss G: 0.3329\n",
      "Epoch [4/50Loss D: 0.7142, Loss G: 0.3484\n",
      "Epoch [4/50Loss D: 0.7760, Loss G: 0.2707\n",
      "Epoch [4/50Loss D: 0.5966, Loss G: 0.4276\n",
      "Epoch [4/50Loss D: 0.6689, Loss G: 0.4344\n",
      "Epoch [4/50Loss D: 0.7928, Loss G: 0.2845\n",
      "Epoch [4/50Loss D: 0.6767, Loss G: 0.3900\n",
      "Epoch [4/50Loss D: 0.8842, Loss G: 0.2289\n",
      "Epoch [4/50Loss D: 0.6811, Loss G: 0.3819\n",
      "Epoch [4/50Loss D: 0.6446, Loss G: 0.3962\n",
      "Epoch [4/50Loss D: 0.6813, Loss G: 0.3614\n",
      "Epoch [4/50Loss D: 0.8312, Loss G: 0.2633\n",
      "Epoch [4/50Loss D: 0.7025, Loss G: 0.3627\n",
      "Epoch [4/50Loss D: 0.5603, Loss G: 0.5069\n",
      "Epoch [4/50Loss D: 0.7996, Loss G: 0.2718\n",
      "Epoch [4/50Loss D: 0.7802, Loss G: 0.2744\n",
      "Epoch [5/50Loss D: 0.6463, Loss G: 0.3905\n",
      "Epoch [5/50Loss D: 0.8220, Loss G: 0.2476\n",
      "Epoch [5/50Loss D: 0.7211, Loss G: 0.3427\n",
      "Epoch [5/50Loss D: 0.8571, Loss G: 0.2421\n",
      "Epoch [5/50Loss D: 0.6153, Loss G: 0.4494\n",
      "Epoch [5/50Loss D: 0.6220, Loss G: 0.4304\n",
      "Epoch [5/50Loss D: 0.9078, Loss G: 0.2079\n",
      "Epoch [5/50Loss D: 0.5791, Loss G: 0.5189\n",
      "Epoch [5/50Loss D: 0.8074, Loss G: 0.2672\n",
      "Epoch [5/50Loss D: 0.6766, Loss G: 0.3852\n",
      "Epoch [5/50Loss D: 0.8924, Loss G: 0.2094\n",
      "Epoch [5/50Loss D: 0.7105, Loss G: 0.3480\n",
      "Epoch [5/50Loss D: 0.7426, Loss G: 0.3090\n",
      "Epoch [5/50Loss D: 0.6409, Loss G: 0.3840\n",
      "Epoch [5/50Loss D: 0.6522, Loss G: 0.3806\n",
      "Epoch [5/50Loss D: 0.8684, Loss G: 0.2393\n",
      "Epoch [5/50Loss D: 0.6547, Loss G: 0.4120\n",
      "Epoch [5/50Loss D: 0.7252, Loss G: 0.3271\n",
      "Epoch [5/50Loss D: 0.7364, Loss G: 0.3183\n",
      "Epoch [5/50Loss D: 0.6117, Loss G: 0.4257\n",
      "Epoch [5/50Loss D: 0.8287, Loss G: 0.2651\n",
      "Epoch [5/50Loss D: 0.6462, Loss G: 0.4195\n",
      "Epoch [5/50Loss D: 0.7623, Loss G: 0.3037\n",
      "Epoch [5/50Loss D: 0.7427, Loss G: 0.3343\n",
      "Epoch [5/50Loss D: 0.5807, Loss G: 0.4614\n",
      "Epoch [5/50Loss D: 0.8844, Loss G: 0.2231\n",
      "Epoch [5/50Loss D: 0.6509, Loss G: 0.4783\n",
      "Epoch [5/50Loss D: 0.6029, Loss G: 0.4907\n",
      "Epoch [5/50Loss D: 0.7585, Loss G: 0.2990\n",
      "Epoch [5/50Loss D: 0.6850, Loss G: 0.4105\n",
      "Epoch [5/50Loss D: 0.7664, Loss G: 0.2879\n",
      "Epoch [5/50Loss D: 0.7243, Loss G: 0.3268\n",
      "Epoch [5/50Loss D: 0.8131, Loss G: 0.2928\n",
      "Epoch [5/50Loss D: 0.6725, Loss G: 0.4213\n",
      "Epoch [5/50Loss D: 0.6768, Loss G: 0.3616\n",
      "Epoch [5/50Loss D: 0.7576, Loss G: 0.3229\n",
      "Epoch [5/50Loss D: 0.6643, Loss G: 0.3836\n",
      "Epoch [5/50Loss D: 0.6413, Loss G: 0.4012\n",
      "Epoch [5/50Loss D: 0.6857, Loss G: 0.3840\n",
      "Epoch [5/50Loss D: 0.6335, Loss G: 0.4452\n",
      "Epoch [5/50Loss D: 0.7198, Loss G: 0.3287\n",
      "Epoch [5/50Loss D: 0.7000, Loss G: 0.3323\n",
      "Epoch [5/50Loss D: 0.7081, Loss G: 0.3791\n",
      "Epoch [5/50Loss D: 0.6744, Loss G: 0.3634\n",
      "Epoch [5/50Loss D: 0.6437, Loss G: 0.3816\n",
      "Epoch [5/50Loss D: 0.8595, Loss G: 0.2380\n",
      "Epoch [5/50Loss D: 0.6630, Loss G: 0.3912\n",
      "Epoch [5/50Loss D: 0.7563, Loss G: 0.2985\n",
      "Epoch [5/50Loss D: 0.7111, Loss G: 0.3490\n",
      "Epoch [5/50Loss D: 0.7072, Loss G: 0.3664\n",
      "Epoch [5/50Loss D: 0.7040, Loss G: 0.3449\n",
      "Epoch [5/50Loss D: 0.5974, Loss G: 0.4469\n",
      "Epoch [5/50Loss D: 0.6448, Loss G: 0.3880\n",
      "Epoch [5/50Loss D: 0.8369, Loss G: 0.2448\n",
      "Epoch [5/50Loss D: 0.7348, Loss G: 0.3186\n",
      "Epoch [5/50Loss D: 0.6959, Loss G: 0.3511\n",
      "Epoch [5/50Loss D: 0.6303, Loss G: 0.4353\n",
      "Epoch [5/50Loss D: 0.7658, Loss G: 0.2813\n",
      "Epoch [5/50Loss D: 0.8739, Loss G: 0.2254\n",
      "Epoch [5/50Loss D: 0.7407, Loss G: 0.3131\n",
      "Epoch [5/50Loss D: 0.8173, Loss G: 0.2605\n",
      "Epoch [5/50Loss D: 0.5120, Loss G: 0.5533\n",
      "Epoch [5/50Loss D: 0.9238, Loss G: 0.2079\n",
      "Epoch [5/50Loss D: 0.7035, Loss G: 0.3635\n",
      "Epoch [5/50Loss D: 0.7228, Loss G: 0.3374\n",
      "Epoch [5/50Loss D: 0.9519, Loss G: 0.1855\n",
      "Epoch [5/50Loss D: 0.5982, Loss G: 0.4675\n",
      "Epoch [5/50Loss D: 0.6130, Loss G: 0.4443\n",
      "Epoch [5/50Loss D: 0.7833, Loss G: 0.2887\n",
      "Epoch [5/50Loss D: 0.7659, Loss G: 0.3053\n",
      "Epoch [5/50Loss D: 0.7235, Loss G: 0.3480\n",
      "Epoch [5/50Loss D: 0.6783, Loss G: 0.3820\n",
      "Epoch [5/50Loss D: 0.5938, Loss G: 0.5079\n",
      "Epoch [5/50Loss D: 0.7305, Loss G: 0.3358\n",
      "Epoch [5/50Loss D: 0.8019, Loss G: 0.2590\n",
      "Epoch [5/50Loss D: 0.8505, Loss G: 0.2415\n",
      "Epoch [5/50Loss D: 0.7544, Loss G: 0.3385\n",
      "Epoch [5/50Loss D: 0.6435, Loss G: 0.4447\n",
      "Epoch [5/50Loss D: 0.7231, Loss G: 0.3288\n",
      "Epoch [5/50Loss D: 0.7558, Loss G: 0.3043\n",
      "Epoch [5/50Loss D: 0.6794, Loss G: 0.3628\n",
      "Epoch [5/50Loss D: 0.6958, Loss G: 0.3614\n",
      "Epoch [5/50Loss D: 0.7095, Loss G: 0.3239\n",
      "Epoch [5/50Loss D: 0.7143, Loss G: 0.3607\n",
      "Epoch [5/50Loss D: 0.8018, Loss G: 0.2657\n",
      "Epoch [5/50Loss D: 0.6037, Loss G: 0.5361\n",
      "Epoch [5/50Loss D: 0.8235, Loss G: 0.2571\n",
      "Epoch [5/50Loss D: 0.7278, Loss G: 0.3331\n",
      "Epoch [5/50Loss D: 0.6449, Loss G: 0.4144\n",
      "Epoch [5/50Loss D: 0.7163, Loss G: 0.3727\n",
      "Epoch [5/50Loss D: 0.7553, Loss G: 0.3149\n",
      "Epoch [5/50Loss D: 0.7024, Loss G: 0.3676\n",
      "Epoch [5/50Loss D: 0.7881, Loss G: 0.2813\n",
      "Epoch [5/50Loss D: 0.8486, Loss G: 0.2407\n",
      "Epoch [5/50Loss D: 0.6208, Loss G: 0.4870\n",
      "Epoch [5/50Loss D: 0.7464, Loss G: 0.3225\n",
      "Epoch [5/50Loss D: 0.6485, Loss G: 0.3816\n",
      "Epoch [5/50Loss D: 0.8735, Loss G: 0.2214\n",
      "Epoch [5/50Loss D: 0.5858, Loss G: 0.4746\n",
      "Epoch [5/50Loss D: 0.7989, Loss G: 0.2762\n",
      "Epoch [5/50Loss D: 0.6287, Loss G: 0.4448\n",
      "Epoch [5/50Loss D: 0.8368, Loss G: 0.2658\n",
      "Epoch [5/50Loss D: 0.7339, Loss G: 0.3241\n",
      "Epoch [5/50Loss D: 0.5764, Loss G: 0.4896\n",
      "Epoch [5/50Loss D: 0.6140, Loss G: 0.4226\n",
      "Epoch [5/50Loss D: 0.6466, Loss G: 0.3850\n",
      "Epoch [5/50Loss D: 0.7314, Loss G: 0.3640\n",
      "Epoch [5/50Loss D: 0.7254, Loss G: 0.3353\n",
      "Epoch [5/50Loss D: 0.7484, Loss G: 0.2998\n",
      "Epoch [5/50Loss D: 0.7246, Loss G: 0.3063\n",
      "Epoch [5/50Loss D: 0.5722, Loss G: 0.4799\n",
      "Epoch [5/50Loss D: 0.8505, Loss G: 0.2451\n",
      "Epoch [5/50Loss D: 0.6196, Loss G: 0.4204\n",
      "Epoch [5/50Loss D: 0.9403, Loss G: 0.2025\n",
      "Epoch [5/50Loss D: 0.7561, Loss G: 0.3120\n",
      "Epoch [5/50Loss D: 0.6526, Loss G: 0.3996\n",
      "Epoch [5/50Loss D: 0.6372, Loss G: 0.4264\n",
      "Epoch [5/50Loss D: 0.5711, Loss G: 0.4775\n",
      "Epoch [5/50Loss D: 0.9123, Loss G: 0.2088\n",
      "Epoch [5/50Loss D: 0.7631, Loss G: 0.3071\n",
      "Epoch [5/50Loss D: 0.7635, Loss G: 0.3094\n",
      "Epoch [5/50Loss D: 0.7384, Loss G: 0.3277\n",
      "Epoch [5/50Loss D: 0.6828, Loss G: 0.3563\n",
      "Epoch [5/50Loss D: 0.6232, Loss G: 0.3967\n",
      "Epoch [5/50Loss D: 0.6796, Loss G: 0.3476\n",
      "Epoch [5/50Loss D: 0.7409, Loss G: 0.3120\n",
      "Epoch [5/50Loss D: 0.6424, Loss G: 0.4726\n",
      "Epoch [5/50Loss D: 0.8048, Loss G: 0.3213\n",
      "Epoch [5/50Loss D: 0.7341, Loss G: 0.3323\n",
      "Epoch [5/50Loss D: 0.7635, Loss G: 0.3024\n",
      "Epoch [5/50Loss D: 0.7754, Loss G: 0.2849\n",
      "Epoch [5/50Loss D: 0.8052, Loss G: 0.2685\n",
      "Epoch [5/50Loss D: 0.8046, Loss G: 0.2675\n",
      "Epoch [5/50Loss D: 0.7434, Loss G: 0.3193\n",
      "Epoch [5/50Loss D: 0.8606, Loss G: 0.2357\n",
      "Epoch [5/50Loss D: 0.6869, Loss G: 0.3711\n",
      "Epoch [5/50Loss D: 0.6308, Loss G: 0.4304\n",
      "Epoch [5/50Loss D: 0.7038, Loss G: 0.3340\n",
      "Epoch [5/50Loss D: 0.7636, Loss G: 0.3073\n",
      "Epoch [5/50Loss D: 0.6295, Loss G: 0.4237\n",
      "Epoch [5/50Loss D: 0.7353, Loss G: 0.3299\n",
      "Epoch [5/50Loss D: 0.6439, Loss G: 0.4324\n",
      "Epoch [5/50Loss D: 0.6772, Loss G: 0.3739\n",
      "Epoch [5/50Loss D: 0.6502, Loss G: 0.4460\n",
      "Epoch [5/50Loss D: 0.7114, Loss G: 0.3487\n",
      "Epoch [5/50Loss D: 0.7485, Loss G: 0.3161\n",
      "Epoch [5/50Loss D: 0.7554, Loss G: 0.3155\n",
      "Epoch [5/50Loss D: 0.6927, Loss G: 0.3586\n",
      "Epoch [5/50Loss D: 0.9101, Loss G: 0.2069\n",
      "Epoch [5/50Loss D: 0.7835, Loss G: 0.2865\n",
      "Epoch [5/50Loss D: 0.6923, Loss G: 0.3450\n",
      "Epoch [5/50Loss D: 0.6611, Loss G: 0.4094\n",
      "Epoch [5/50Loss D: 0.7545, Loss G: 0.3359\n",
      "Epoch [5/50Loss D: 0.7542, Loss G: 0.3008\n",
      "Epoch [5/50Loss D: 0.6463, Loss G: 0.4527\n",
      "Epoch [5/50Loss D: 0.7332, Loss G: 0.3244\n",
      "Epoch [5/50Loss D: 0.7152, Loss G: 0.3326\n",
      "Epoch [5/50Loss D: 0.9969, Loss G: 0.1759\n",
      "Epoch [5/50Loss D: 0.6743, Loss G: 0.3901\n",
      "Epoch [5/50Loss D: 0.7625, Loss G: 0.3185\n",
      "Epoch [5/50Loss D: 0.8191, Loss G: 0.2817\n",
      "Epoch [5/50Loss D: 0.7100, Loss G: 0.3598\n",
      "Epoch [5/50Loss D: 0.7539, Loss G: 0.3199\n",
      "Epoch [5/50Loss D: 0.6886, Loss G: 0.3627\n",
      "Epoch [5/50Loss D: 0.6725, Loss G: 0.3751\n",
      "Epoch [5/50Loss D: 0.7167, Loss G: 0.3333\n",
      "Epoch [5/50Loss D: 0.6971, Loss G: 0.4040\n",
      "Epoch [5/50Loss D: 0.7527, Loss G: 0.3105\n",
      "Epoch [5/50Loss D: 0.7375, Loss G: 0.3196\n",
      "Epoch [5/50Loss D: 0.6491, Loss G: 0.4076\n",
      "Epoch [5/50Loss D: 0.7038, Loss G: 0.3391\n",
      "Epoch [5/50Loss D: 0.7800, Loss G: 0.2873\n",
      "Epoch [5/50Loss D: 0.6991, Loss G: 0.3706\n",
      "Epoch [5/50Loss D: 0.6326, Loss G: 0.4425\n",
      "Epoch [5/50Loss D: 0.6618, Loss G: 0.4001\n",
      "Epoch [5/50Loss D: 0.7748, Loss G: 0.3012\n",
      "Epoch [5/50Loss D: 0.8019, Loss G: 0.2688\n",
      "Epoch [5/50Loss D: 0.8269, Loss G: 0.2515\n",
      "Epoch [5/50Loss D: 0.7087, Loss G: 0.3394\n",
      "Epoch [5/50Loss D: 0.6675, Loss G: 0.3908\n",
      "Epoch [5/50Loss D: 0.6815, Loss G: 0.4084\n",
      "Epoch [5/50Loss D: 0.6647, Loss G: 0.3824\n",
      "Epoch [5/50Loss D: 0.6309, Loss G: 0.4250\n",
      "Epoch [5/50Loss D: 0.8731, Loss G: 0.2378\n",
      "Epoch [5/50Loss D: 0.8367, Loss G: 0.2529\n",
      "Epoch [5/50Loss D: 0.6813, Loss G: 0.4077\n",
      "Epoch [5/50Loss D: 0.6774, Loss G: 0.3802\n",
      "Epoch [5/50Loss D: 0.7272, Loss G: 0.3336\n",
      "Epoch [6/50Loss D: 0.7213, Loss G: 0.3476\n",
      "Epoch [6/50Loss D: 0.6585, Loss G: 0.3912\n",
      "Epoch [6/50Loss D: 0.6783, Loss G: 0.3843\n",
      "Epoch [6/50Loss D: 0.7295, Loss G: 0.3273\n",
      "Epoch [6/50Loss D: 0.8570, Loss G: 0.2408\n",
      "Epoch [6/50Loss D: 0.6933, Loss G: 0.3759\n",
      "Epoch [6/50Loss D: 0.6977, Loss G: 0.3610\n",
      "Epoch [6/50Loss D: 0.7867, Loss G: 0.2781\n",
      "Epoch [6/50Loss D: 0.6803, Loss G: 0.3722\n",
      "Epoch [6/50Loss D: 0.8092, Loss G: 0.2824\n",
      "Epoch [6/50Loss D: 0.7606, Loss G: 0.2989\n",
      "Epoch [6/50Loss D: 0.6504, Loss G: 0.4034\n",
      "Epoch [6/50Loss D: 0.7491, Loss G: 0.3097\n",
      "Epoch [6/50Loss D: 0.6452, Loss G: 0.3834\n",
      "Epoch [6/50Loss D: 0.6435, Loss G: 0.4011\n",
      "Epoch [6/50Loss D: 0.7281, Loss G: 0.3365\n",
      "Epoch [6/50Loss D: 0.6970, Loss G: 0.3665\n",
      "Epoch [6/50Loss D: 0.7957, Loss G: 0.2724\n",
      "Epoch [6/50Loss D: 0.5711, Loss G: 0.4789\n",
      "Epoch [6/50Loss D: 0.7903, Loss G: 0.2751\n",
      "Epoch [6/50Loss D: 0.6905, Loss G: 0.3482\n",
      "Epoch [6/50Loss D: 0.7305, Loss G: 0.3093\n",
      "Epoch [6/50Loss D: 0.6670, Loss G: 0.3728\n",
      "Epoch [6/50Loss D: 0.6154, Loss G: 0.4335\n",
      "Epoch [6/50Loss D: 0.6893, Loss G: 0.3586\n",
      "Epoch [6/50Loss D: 0.7274, Loss G: 0.3248\n",
      "Epoch [6/50Loss D: 0.5546, Loss G: 0.5160\n",
      "Epoch [6/50Loss D: 0.8271, Loss G: 0.2678\n",
      "Epoch [6/50Loss D: 0.7961, Loss G: 0.2756\n",
      "Epoch [6/50Loss D: 0.8080, Loss G: 0.2526\n",
      "Epoch [6/50Loss D: 0.7843, Loss G: 0.2780\n",
      "Epoch [6/50Loss D: 0.6230, Loss G: 0.4273\n",
      "Epoch [6/50Loss D: 0.6953, Loss G: 0.3508\n",
      "Epoch [6/50Loss D: 0.6718, Loss G: 0.3719\n",
      "Epoch [6/50Loss D: 0.7229, Loss G: 0.3543\n",
      "Epoch [6/50Loss D: 0.8799, Loss G: 0.2203\n",
      "Epoch [6/50Loss D: 0.6796, Loss G: 0.3539\n",
      "Epoch [6/50Loss D: 0.8029, Loss G: 0.2818\n",
      "Epoch [6/50Loss D: 0.7165, Loss G: 0.3331\n",
      "Epoch [6/50Loss D: 0.5646, Loss G: 0.5075\n",
      "Epoch [6/50Loss D: 0.6969, Loss G: 0.3515\n",
      "Epoch [6/50Loss D: 0.7883, Loss G: 0.2729\n",
      "Epoch [6/50Loss D: 0.7651, Loss G: 0.3030\n",
      "Epoch [6/50Loss D: 0.6350, Loss G: 0.4485\n",
      "Epoch [6/50Loss D: 0.7893, Loss G: 0.2692\n",
      "Epoch [6/50Loss D: 0.6688, Loss G: 0.3877\n",
      "Epoch [6/50Loss D: 0.7734, Loss G: 0.2884\n",
      "Epoch [6/50Loss D: 0.6882, Loss G: 0.3802\n",
      "Epoch [6/50Loss D: 0.7033, Loss G: 0.3408\n",
      "Epoch [6/50Loss D: 0.7179, Loss G: 0.3228\n",
      "Epoch [6/50Loss D: 0.6343, Loss G: 0.4340\n",
      "Epoch [6/50Loss D: 0.7158, Loss G: 0.3548\n",
      "Epoch [6/50Loss D: 0.7734, Loss G: 0.2900\n",
      "Epoch [6/50Loss D: 0.6487, Loss G: 0.3929\n",
      "Epoch [6/50Loss D: 0.7067, Loss G: 0.3330\n",
      "Epoch [6/50Loss D: 0.6950, Loss G: 0.3520\n",
      "Epoch [6/50Loss D: 0.8317, Loss G: 0.2475\n",
      "Epoch [6/50Loss D: 0.6767, Loss G: 0.3610\n",
      "Epoch [6/50Loss D: 0.8454, Loss G: 0.2421\n",
      "Epoch [6/50Loss D: 0.6308, Loss G: 0.4455\n",
      "Epoch [6/50Loss D: 0.8249, Loss G: 0.2643\n",
      "Epoch [6/50Loss D: 0.6222, Loss G: 0.4282\n",
      "Epoch [6/50Loss D: 0.6376, Loss G: 0.4001\n",
      "Epoch [6/50Loss D: 0.6785, Loss G: 0.4039\n",
      "Epoch [6/50Loss D: 0.7336, Loss G: 0.3318\n",
      "Epoch [6/50Loss D: 0.6015, Loss G: 0.4591\n",
      "Epoch [6/50Loss D: 0.7506, Loss G: 0.3035\n",
      "Epoch [6/50Loss D: 0.5996, Loss G: 0.4516\n",
      "Epoch [6/50Loss D: 0.7065, Loss G: 0.3230\n",
      "Epoch [6/50Loss D: 0.8186, Loss G: 0.2570\n",
      "Epoch [6/50Loss D: 0.5304, Loss G: 0.5999\n",
      "Epoch [6/50Loss D: 0.7512, Loss G: 0.2980\n",
      "Epoch [6/50Loss D: 0.7260, Loss G: 0.3348\n",
      "Epoch [6/50Loss D: 0.8169, Loss G: 0.2821\n",
      "Epoch [6/50Loss D: 0.7319, Loss G: 0.3299\n",
      "Epoch [6/50Loss D: 0.8096, Loss G: 0.2789\n",
      "Epoch [6/50Loss D: 0.6810, Loss G: 0.3566\n",
      "Epoch [6/50Loss D: 0.6795, Loss G: 0.3622\n",
      "Epoch [6/50Loss D: 0.7033, Loss G: 0.3334\n",
      "Epoch [6/50Loss D: 0.9507, Loss G: 0.1936\n",
      "Epoch [6/50Loss D: 0.6237, Loss G: 0.4962\n",
      "Epoch [6/50Loss D: 0.6208, Loss G: 0.4429\n",
      "Epoch [6/50Loss D: 0.8987, Loss G: 0.2166\n",
      "Epoch [6/50Loss D: 0.6840, Loss G: 0.3739\n",
      "Epoch [6/50Loss D: 0.7225, Loss G: 0.3535\n",
      "Epoch [6/50Loss D: 0.7197, Loss G: 0.3329\n",
      "Epoch [6/50Loss D: 0.6188, Loss G: 0.4151\n",
      "Epoch [6/50Loss D: 0.7111, Loss G: 0.3473\n",
      "Epoch [6/50Loss D: 1.0123, Loss G: 0.1651\n",
      "Epoch [6/50Loss D: 0.8313, Loss G: 0.2681\n",
      "Epoch [6/50Loss D: 0.7060, Loss G: 0.3754\n",
      "Epoch [6/50Loss D: 0.6181, Loss G: 0.4420\n",
      "Epoch [6/50Loss D: 0.9236, Loss G: 0.1997\n",
      "Epoch [6/50Loss D: 0.6307, Loss G: 0.4499\n",
      "Epoch [6/50Loss D: 0.6761, Loss G: 0.3817\n",
      "Epoch [6/50Loss D: 0.6806, Loss G: 0.3558\n",
      "Epoch [6/50Loss D: 0.7022, Loss G: 0.3363\n",
      "Epoch [6/50Loss D: 0.7816, Loss G: 0.2994\n",
      "Epoch [6/50Loss D: 0.6790, Loss G: 0.3774\n",
      "Epoch [6/50Loss D: 0.6392, Loss G: 0.4107\n",
      "Epoch [6/50Loss D: 0.9976, Loss G: 0.1676\n",
      "Epoch [6/50Loss D: 0.7260, Loss G: 0.3739\n",
      "Epoch [6/50Loss D: 0.5997, Loss G: 0.4741\n",
      "Epoch [6/50Loss D: 0.8434, Loss G: 0.2537\n",
      "Epoch [6/50Loss D: 0.6480, Loss G: 0.3738\n",
      "Epoch [6/50Loss D: 0.6581, Loss G: 0.3850\n",
      "Epoch [6/50Loss D: 0.7710, Loss G: 0.2831\n",
      "Epoch [6/50Loss D: 0.6499, Loss G: 0.3935\n",
      "Epoch [6/50Loss D: 0.7888, Loss G: 0.3157\n",
      "Epoch [6/50Loss D: 0.7636, Loss G: 0.2918\n",
      "Epoch [6/50Loss D: 0.5734, Loss G: 0.4940\n",
      "Epoch [6/50Loss D: 0.7280, Loss G: 0.3164\n",
      "Epoch [6/50Loss D: 0.5655, Loss G: 0.5336\n",
      "Epoch [6/50Loss D: 0.8685, Loss G: 0.2395\n",
      "Epoch [6/50Loss D: 0.7381, Loss G: 0.3191\n",
      "Epoch [6/50Loss D: 0.6173, Loss G: 0.4381\n",
      "Epoch [6/50Loss D: 0.6939, Loss G: 0.3446\n",
      "Epoch [6/50Loss D: 0.8216, Loss G: 0.2590\n",
      "Epoch [6/50Loss D: 0.6658, Loss G: 0.4144\n",
      "Epoch [6/50Loss D: 0.8092, Loss G: 0.2768\n",
      "Epoch [6/50Loss D: 0.7268, Loss G: 0.3286\n",
      "Epoch [6/50Loss D: 0.7301, Loss G: 0.3262\n",
      "Epoch [6/50Loss D: 0.6621, Loss G: 0.3752\n",
      "Epoch [6/50Loss D: 0.7286, Loss G: 0.3188\n",
      "Epoch [6/50Loss D: 0.8938, Loss G: 0.2142\n",
      "Epoch [6/50Loss D: 0.7054, Loss G: 0.3446\n",
      "Epoch [6/50Loss D: 0.7662, Loss G: 0.3063\n",
      "Epoch [6/50Loss D: 0.6891, Loss G: 0.3515\n",
      "Epoch [6/50Loss D: 0.6182, Loss G: 0.4105\n",
      "Epoch [6/50Loss D: 0.7365, Loss G: 0.3074\n",
      "Epoch [6/50Loss D: 0.7250, Loss G: 0.3152\n",
      "Epoch [6/50Loss D: 0.6644, Loss G: 0.4091\n",
      "Epoch [6/50Loss D: 0.7013, Loss G: 0.3517\n",
      "Epoch [6/50Loss D: 0.6438, Loss G: 0.3879\n",
      "Epoch [6/50Loss D: 1.0183, Loss G: 0.1540\n",
      "Epoch [6/50Loss D: 0.7601, Loss G: 0.3004\n",
      "Epoch [6/50Loss D: 0.6663, Loss G: 0.4026\n",
      "Epoch [6/50Loss D: 0.7142, Loss G: 0.3426\n",
      "Epoch [6/50Loss D: 0.7721, Loss G: 0.2985\n",
      "Epoch [6/50Loss D: 0.8912, Loss G: 0.2371\n",
      "Epoch [6/50Loss D: 0.6976, Loss G: 0.3683\n",
      "Epoch [6/50Loss D: 0.6414, Loss G: 0.4115\n",
      "Epoch [6/50Loss D: 0.7417, Loss G: 0.3105\n",
      "Epoch [6/50Loss D: 0.7410, Loss G: 0.3185\n",
      "Epoch [6/50Loss D: 0.7304, Loss G: 0.3300\n",
      "Epoch [6/50Loss D: 0.7572, Loss G: 0.3034\n",
      "Epoch [6/50Loss D: 0.6780, Loss G: 0.3939\n",
      "Epoch [6/50Loss D: 0.7879, Loss G: 0.2911\n",
      "Epoch [6/50Loss D: 0.7861, Loss G: 0.2671\n",
      "Epoch [6/50Loss D: 0.8165, Loss G: 0.2487\n",
      "Epoch [6/50Loss D: 0.7875, Loss G: 0.2723\n",
      "Epoch [6/50Loss D: 0.7839, Loss G: 0.2741\n",
      "Epoch [6/50Loss D: 0.6698, Loss G: 0.3831\n",
      "Epoch [6/50Loss D: 0.7105, Loss G: 0.3588\n",
      "Epoch [6/50Loss D: 0.6734, Loss G: 0.3738\n",
      "Epoch [6/50Loss D: 0.5979, Loss G: 0.4568\n",
      "Epoch [6/50Loss D: 0.6671, Loss G: 0.3904\n",
      "Epoch [6/50Loss D: 0.6685, Loss G: 0.3718\n",
      "Epoch [6/50Loss D: 0.8318, Loss G: 0.2461\n",
      "Epoch [6/50Loss D: 0.6933, Loss G: 0.3348\n",
      "Epoch [6/50Loss D: 0.9775, Loss G: 0.2053\n",
      "Epoch [6/50Loss D: 0.6388, Loss G: 0.4318\n",
      "Epoch [6/50Loss D: 0.7154, Loss G: 0.3389\n",
      "Epoch [6/50Loss D: 0.7158, Loss G: 0.3306\n",
      "Epoch [6/50Loss D: 0.7715, Loss G: 0.2922\n",
      "Epoch [6/50Loss D: 0.8077, Loss G: 0.2732\n",
      "Epoch [6/50Loss D: 0.6751, Loss G: 0.3868\n",
      "Epoch [6/50Loss D: 0.6289, Loss G: 0.4033\n",
      "Epoch [6/50Loss D: 0.8162, Loss G: 0.2583\n",
      "Epoch [6/50Loss D: 0.7438, Loss G: 0.3366\n",
      "Epoch [6/50Loss D: 0.7630, Loss G: 0.3191\n",
      "Epoch [6/50Loss D: 0.6194, Loss G: 0.4252\n",
      "Epoch [6/50Loss D: 0.6188, Loss G: 0.4184\n",
      "Epoch [6/50Loss D: 0.7909, Loss G: 0.2601\n",
      "Epoch [6/50Loss D: 0.7932, Loss G: 0.2659\n",
      "Epoch [6/50Loss D: 0.6306, Loss G: 0.4405\n",
      "Epoch [6/50Loss D: 0.6922, Loss G: 0.3985\n",
      "Epoch [6/50Loss D: 0.7233, Loss G: 0.3283\n",
      "Epoch [6/50Loss D: 0.7164, Loss G: 0.3419\n",
      "Epoch [6/50Loss D: 0.7439, Loss G: 0.3089\n",
      "Epoch [6/50Loss D: 0.5473, Loss G: 0.5082\n",
      "Epoch [6/50Loss D: 0.8011, Loss G: 0.2757\n",
      "Epoch [6/50Loss D: 0.7669, Loss G: 0.2998\n",
      "Epoch [6/50Loss D: 0.7949, Loss G: 0.2964\n",
      "Epoch [6/50Loss D: 0.7788, Loss G: 0.2905\n",
      "Epoch [6/50Loss D: 0.7238, Loss G: 0.3204\n",
      "Epoch [6/50Loss D: 0.7777, Loss G: 0.2688\n",
      "Epoch [6/50Loss D: 0.7335, Loss G: 0.3392\n",
      "Epoch [7/50Loss D: 0.7641, Loss G: 0.2774\n",
      "Epoch [7/50Loss D: 0.6202, Loss G: 0.4424\n",
      "Epoch [7/50Loss D: 0.5884, Loss G: 0.5071\n",
      "Epoch [7/50Loss D: 0.6826, Loss G: 0.3486\n",
      "Epoch [7/50Loss D: 0.7227, Loss G: 0.3092\n",
      "Epoch [7/50Loss D: 0.5844, Loss G: 0.4600\n",
      "Epoch [7/50Loss D: 0.6991, Loss G: 0.3509\n",
      "Epoch [7/50Loss D: 0.6671, Loss G: 0.3561\n",
      "Epoch [7/50Loss D: 0.6401, Loss G: 0.4148\n",
      "Epoch [7/50Loss D: 0.6253, Loss G: 0.3979\n",
      "Epoch [7/50Loss D: 0.8025, Loss G: 0.2726\n",
      "Epoch [7/50Loss D: 0.6515, Loss G: 0.4145\n",
      "Epoch [7/50Loss D: 0.7153, Loss G: 0.3273\n",
      "Epoch [7/50Loss D: 0.7319, Loss G: 0.3187\n",
      "Epoch [7/50Loss D: 0.8484, Loss G: 0.2485\n",
      "Epoch [7/50Loss D: 0.5361, Loss G: 0.6199\n",
      "Epoch [7/50Loss D: 0.6121, Loss G: 0.4819\n",
      "Epoch [7/50Loss D: 0.5904, Loss G: 0.5037\n",
      "Epoch [7/50Loss D: 0.6232, Loss G: 0.4707\n",
      "Epoch [7/50Loss D: 0.6422, Loss G: 0.4184\n",
      "Epoch [7/50Loss D: 0.7388, Loss G: 0.3331\n",
      "Epoch [7/50Loss D: 0.6661, Loss G: 0.3689\n",
      "Epoch [7/50Loss D: 0.5922, Loss G: 0.4400\n",
      "Epoch [7/50Loss D: 0.7889, Loss G: 0.2805\n",
      "Epoch [7/50Loss D: 0.7790, Loss G: 0.2791\n",
      "Epoch [7/50Loss D: 0.7280, Loss G: 0.3417\n",
      "Epoch [7/50Loss D: 0.7266, Loss G: 0.3159\n",
      "Epoch [7/50Loss D: 0.7408, Loss G: 0.3051\n",
      "Epoch [7/50Loss D: 0.5693, Loss G: 0.4984\n",
      "Epoch [7/50Loss D: 0.7741, Loss G: 0.2777\n",
      "Epoch [7/50Loss D: 0.8036, Loss G: 0.2877\n",
      "Epoch [7/50Loss D: 0.6424, Loss G: 0.4093\n",
      "Epoch [7/50Loss D: 0.7484, Loss G: 0.3640\n",
      "Epoch [7/50Loss D: 0.9076, Loss G: 0.2091\n",
      "Epoch [7/50Loss D: 0.7270, Loss G: 0.3246\n",
      "Epoch [7/50Loss D: 0.7309, Loss G: 0.3283\n",
      "Epoch [7/50Loss D: 0.6188, Loss G: 0.4231\n",
      "Epoch [7/50Loss D: 0.6572, Loss G: 0.3851\n",
      "Epoch [7/50Loss D: 0.6568, Loss G: 0.3767\n",
      "Epoch [7/50Loss D: 0.5840, Loss G: 0.4456\n",
      "Epoch [7/50Loss D: 0.7483, Loss G: 0.3368\n",
      "Epoch [7/50Loss D: 0.8645, Loss G: 0.2623\n",
      "Epoch [7/50Loss D: 0.6971, Loss G: 0.3543\n",
      "Epoch [7/50Loss D: 0.8318, Loss G: 0.2456\n",
      "Epoch [7/50Loss D: 0.5811, Loss G: 0.4868\n",
      "Epoch [7/50Loss D: 0.7663, Loss G: 0.3086\n",
      "Epoch [7/50Loss D: 0.6781, Loss G: 0.3949\n",
      "Epoch [7/50Loss D: 0.7747, Loss G: 0.2838\n",
      "Epoch [7/50Loss D: 0.7777, Loss G: 0.2698\n",
      "Epoch [7/50Loss D: 0.6231, Loss G: 0.4321\n",
      "Epoch [7/50Loss D: 0.6905, Loss G: 0.3485\n",
      "Epoch [7/50Loss D: 0.7303, Loss G: 0.3738\n",
      "Epoch [7/50Loss D: 0.6231, Loss G: 0.5146\n",
      "Epoch [7/50Loss D: 0.8806, Loss G: 0.2130\n",
      "Epoch [7/50Loss D: 0.7509, Loss G: 0.3322\n",
      "Epoch [7/50Loss D: 0.6176, Loss G: 0.5083\n",
      "Epoch [7/50Loss D: 0.6047, Loss G: 0.4673\n",
      "Epoch [7/50Loss D: 0.8047, Loss G: 0.2641\n",
      "Epoch [7/50Loss D: 0.6328, Loss G: 0.4029\n",
      "Epoch [7/50Loss D: 0.9210, Loss G: 0.1932\n",
      "Epoch [7/50Loss D: 0.6307, Loss G: 0.4698\n",
      "Epoch [7/50Loss D: 0.6578, Loss G: 0.4027\n",
      "Epoch [7/50Loss D: 0.7557, Loss G: 0.3030\n",
      "Epoch [7/50Loss D: 0.7718, Loss G: 0.2762\n",
      "Epoch [7/50Loss D: 0.8070, Loss G: 0.2660\n",
      "Epoch [7/50Loss D: 0.7609, Loss G: 0.2963\n",
      "Epoch [7/50Loss D: 0.7164, Loss G: 0.3414\n",
      "Epoch [7/50Loss D: 0.6533, Loss G: 0.4062\n",
      "Epoch [7/50Loss D: 0.7508, Loss G: 0.3227\n",
      "Epoch [7/50Loss D: 0.7334, Loss G: 0.3266\n",
      "Epoch [7/50Loss D: 0.7097, Loss G: 0.3745\n",
      "Epoch [7/50Loss D: 0.6827, Loss G: 0.3724\n",
      "Epoch [7/50Loss D: 0.7026, Loss G: 0.3342\n",
      "Epoch [7/50Loss D: 0.6543, Loss G: 0.3794\n",
      "Epoch [7/50Loss D: 0.7801, Loss G: 0.3013\n",
      "Epoch [7/50Loss D: 0.5891, Loss G: 0.5151\n",
      "Epoch [7/50Loss D: 0.7923, Loss G: 0.2747\n",
      "Epoch [7/50Loss D: 0.7944, Loss G: 0.2763\n",
      "Epoch [7/50Loss D: 0.6217, Loss G: 0.4193\n",
      "Epoch [7/50Loss D: 0.6499, Loss G: 0.3847\n",
      "Epoch [7/50Loss D: 0.7005, Loss G: 0.3590\n",
      "Epoch [7/50Loss D: 0.8849, Loss G: 0.2253\n",
      "Epoch [7/50Loss D: 0.6227, Loss G: 0.4237\n",
      "Epoch [7/50Loss D: 0.6110, Loss G: 0.4247\n",
      "Epoch [7/50Loss D: 0.8029, Loss G: 0.2812\n",
      "Epoch [7/50Loss D: 0.8679, Loss G: 0.2274\n",
      "Epoch [7/50Loss D: 1.0247, Loss G: 0.1525\n",
      "Epoch [7/50Loss D: 0.7481, Loss G: 0.3030\n",
      "Epoch [7/50Loss D: 0.7149, Loss G: 0.3443\n",
      "Epoch [7/50Loss D: 0.6412, Loss G: 0.4545\n",
      "Epoch [7/50Loss D: 0.7166, Loss G: 0.3200\n",
      "Epoch [7/50Loss D: 0.6817, Loss G: 0.3592\n",
      "Epoch [7/50Loss D: 1.0436, Loss G: 0.1661\n",
      "Epoch [7/50Loss D: 0.7361, Loss G: 0.3114\n",
      "Epoch [7/50Loss D: 0.6537, Loss G: 0.4239\n",
      "Epoch [7/50Loss D: 0.8660, Loss G: 0.2520\n",
      "Epoch [7/50Loss D: 0.6816, Loss G: 0.3726\n",
      "Epoch [7/50Loss D: 0.6216, Loss G: 0.4243\n",
      "Epoch [7/50Loss D: 0.5844, Loss G: 0.4655\n",
      "Epoch [7/50Loss D: 0.8155, Loss G: 0.2468\n",
      "Epoch [7/50Loss D: 0.7495, Loss G: 0.3169\n",
      "Epoch [7/50Loss D: 0.6262, Loss G: 0.4079\n",
      "Epoch [7/50Loss D: 0.7506, Loss G: 0.3183\n",
      "Epoch [7/50Loss D: 0.6229, Loss G: 0.4289\n",
      "Epoch [7/50Loss D: 0.5720, Loss G: 0.5077\n",
      "Epoch [7/50Loss D: 0.9114, Loss G: 0.1997\n",
      "Epoch [7/50Loss D: 0.6645, Loss G: 0.3630\n",
      "Epoch [7/50Loss D: 0.8017, Loss G: 0.2962\n",
      "Epoch [7/50Loss D: 0.7753, Loss G: 0.2893\n",
      "Epoch [7/50Loss D: 0.7344, Loss G: 0.3268\n",
      "Epoch [7/50Loss D: 0.7059, Loss G: 0.3577\n",
      "Epoch [7/50Loss D: 0.8174, Loss G: 0.2579\n",
      "Epoch [7/50Loss D: 0.7155, Loss G: 0.3312\n",
      "Epoch [7/50Loss D: 0.6931, Loss G: 0.3493\n",
      "Epoch [7/50Loss D: 0.7982, Loss G: 0.2712\n",
      "Epoch [7/50Loss D: 0.5303, Loss G: 0.6068\n",
      "Epoch [7/50Loss D: 0.8771, Loss G: 0.2413\n",
      "Epoch [7/50Loss D: 0.5538, Loss G: 0.5269\n",
      "Epoch [7/50Loss D: 0.6787, Loss G: 0.3335\n",
      "Epoch [7/50Loss D: 0.8054, Loss G: 0.2526\n",
      "Epoch [7/50Loss D: 0.6856, Loss G: 0.3580\n",
      "Epoch [7/50Loss D: 0.7281, Loss G: 0.3459\n",
      "Epoch [7/50Loss D: 0.7070, Loss G: 0.3517\n",
      "Epoch [7/50Loss D: 0.6093, Loss G: 0.4685\n",
      "Epoch [7/50Loss D: 0.9312, Loss G: 0.2010\n",
      "Epoch [7/50Loss D: 0.6973, Loss G: 0.3648\n",
      "Epoch [7/50Loss D: 0.7115, Loss G: 0.4079\n",
      "Epoch [7/50Loss D: 0.7597, Loss G: 0.3224\n",
      "Epoch [7/50Loss D: 0.6133, Loss G: 0.4644\n",
      "Epoch [7/50Loss D: 0.7487, Loss G: 0.3151\n",
      "Epoch [7/50Loss D: 0.8061, Loss G: 0.2789\n",
      "Epoch [7/50Loss D: 0.8351, Loss G: 0.2569\n",
      "Epoch [7/50Loss D: 0.6828, Loss G: 0.3663\n",
      "Epoch [7/50Loss D: 0.7975, Loss G: 0.2586\n",
      "Epoch [7/50Loss D: 0.7705, Loss G: 0.3030\n",
      "Epoch [7/50Loss D: 0.6744, Loss G: 0.3866\n",
      "Epoch [7/50Loss D: 0.7644, Loss G: 0.3093\n",
      "Epoch [7/50Loss D: 0.6056, Loss G: 0.4790\n",
      "Epoch [7/50Loss D: 0.6549, Loss G: 0.3960\n",
      "Epoch [7/50Loss D: 0.6328, Loss G: 0.3947\n",
      "Epoch [7/50Loss D: 0.6935, Loss G: 0.4131\n",
      "Epoch [7/50Loss D: 0.7967, Loss G: 0.3051\n",
      "Epoch [7/50Loss D: 0.5869, Loss G: 0.5319\n",
      "Epoch [7/50Loss D: 0.7749, Loss G: 0.3127\n",
      "Epoch [7/50Loss D: 0.6978, Loss G: 0.3469\n",
      "Epoch [7/50Loss D: 0.7589, Loss G: 0.3111\n",
      "Epoch [7/50Loss D: 0.6042, Loss G: 0.4564\n",
      "Epoch [7/50Loss D: 0.9215, Loss G: 0.1980\n",
      "Epoch [7/50Loss D: 0.8429, Loss G: 0.2389\n",
      "Epoch [7/50Loss D: 0.6515, Loss G: 0.3883\n",
      "Epoch [7/50Loss D: 0.6680, Loss G: 0.4012\n",
      "Epoch [7/50Loss D: 0.7189, Loss G: 0.3381\n",
      "Epoch [7/50Loss D: 0.6843, Loss G: 0.3550\n",
      "Epoch [7/50Loss D: 0.8254, Loss G: 0.2528\n",
      "Epoch [7/50Loss D: 0.9282, Loss G: 0.2287\n",
      "Epoch [7/50Loss D: 0.7296, Loss G: 0.3164\n",
      "Epoch [7/50Loss D: 0.6595, Loss G: 0.3907\n",
      "Epoch [7/50Loss D: 0.8139, Loss G: 0.2795\n",
      "Epoch [7/50Loss D: 0.7352, Loss G: 0.3209\n",
      "Epoch [7/50Loss D: 0.7089, Loss G: 0.3349\n",
      "Epoch [7/50Loss D: 0.6831, Loss G: 0.4384\n",
      "Epoch [7/50Loss D: 0.7838, Loss G: 0.3082\n",
      "Epoch [7/50Loss D: 0.9147, Loss G: 0.2002\n",
      "Epoch [7/50Loss D: 0.6106, Loss G: 0.4337\n",
      "Epoch [7/50Loss D: 0.6706, Loss G: 0.3715\n",
      "Epoch [7/50Loss D: 0.7128, Loss G: 0.3218\n",
      "Epoch [7/50Loss D: 0.7218, Loss G: 0.3690\n",
      "Epoch [7/50Loss D: 0.8803, Loss G: 0.2405\n",
      "Epoch [7/50Loss D: 0.8489, Loss G: 0.3033\n",
      "Epoch [7/50Loss D: 0.6699, Loss G: 0.3949\n",
      "Epoch [7/50Loss D: 0.7006, Loss G: 0.3506\n",
      "Epoch [7/50Loss D: 0.6524, Loss G: 0.4129\n",
      "Epoch [7/50Loss D: 0.8900, Loss G: 0.2170\n",
      "Epoch [7/50Loss D: 0.6910, Loss G: 0.3640\n",
      "Epoch [7/50Loss D: 0.6576, Loss G: 0.4064\n",
      "Epoch [7/50Loss D: 0.7857, Loss G: 0.2672\n",
      "Epoch [7/50Loss D: 0.6394, Loss G: 0.4375\n",
      "Epoch [7/50Loss D: 0.8204, Loss G: 0.2617\n",
      "Epoch [7/50Loss D: 0.7527, Loss G: 0.3060\n",
      "Epoch [7/50Loss D: 0.6948, Loss G: 0.3912\n",
      "Epoch [7/50Loss D: 0.7421, Loss G: 0.3099\n",
      "Epoch [7/50Loss D: 0.7378, Loss G: 0.3453\n",
      "Epoch [7/50Loss D: 0.8865, Loss G: 0.2266\n",
      "Epoch [7/50Loss D: 0.6693, Loss G: 0.3692\n",
      "Epoch [7/50Loss D: 0.6470, Loss G: 0.4275\n",
      "Epoch [7/50Loss D: 0.6257, Loss G: 0.4216\n",
      "Epoch [7/50Loss D: 0.8502, Loss G: 0.2375\n",
      "Epoch [7/50Loss D: 0.9298, Loss G: 0.2049\n",
      "Epoch [8/50Loss D: 0.7140, Loss G: 0.3241\n",
      "Epoch [8/50Loss D: 0.7429, Loss G: 0.2998\n",
      "Epoch [8/50Loss D: 0.6663, Loss G: 0.3499\n",
      "Epoch [8/50Loss D: 0.7772, Loss G: 0.3002\n",
      "Epoch [8/50Loss D: 0.8487, Loss G: 0.2366\n",
      "Epoch [8/50Loss D: 0.7271, Loss G: 0.3221\n",
      "Epoch [8/50Loss D: 0.7624, Loss G: 0.2989\n",
      "Epoch [8/50Loss D: 0.8079, Loss G: 0.2832\n",
      "Epoch [8/50Loss D: 0.6316, Loss G: 0.4586\n",
      "Epoch [8/50Loss D: 0.6725, Loss G: 0.3591\n",
      "Epoch [8/50Loss D: 0.8649, Loss G: 0.2263\n",
      "Epoch [8/50Loss D: 0.7104, Loss G: 0.3605\n",
      "Epoch [8/50Loss D: 0.6885, Loss G: 0.3950\n",
      "Epoch [8/50Loss D: 0.6563, Loss G: 0.3818\n",
      "Epoch [8/50Loss D: 0.7006, Loss G: 0.3536\n",
      "Epoch [8/50Loss D: 0.7128, Loss G: 0.3713\n",
      "Epoch [8/50Loss D: 0.5807, Loss G: 0.4654\n",
      "Epoch [8/50Loss D: 0.7361, Loss G: 0.3248\n",
      "Epoch [8/50Loss D: 0.8692, Loss G: 0.2587\n",
      "Epoch [8/50Loss D: 0.5584, Loss G: 0.5128\n",
      "Epoch [8/50Loss D: 0.9042, Loss G: 0.2042\n",
      "Epoch [8/50Loss D: 0.8063, Loss G: 0.2797\n",
      "Epoch [8/50Loss D: 0.7911, Loss G: 0.2769\n",
      "Epoch [8/50Loss D: 0.7836, Loss G: 0.2672\n",
      "Epoch [8/50Loss D: 0.7911, Loss G: 0.2958\n",
      "Epoch [8/50Loss D: 0.7533, Loss G: 0.3459\n",
      "Epoch [8/50Loss D: 0.7378, Loss G: 0.3287\n",
      "Epoch [8/50Loss D: 0.6360, Loss G: 0.3775\n",
      "Epoch [8/50Loss D: 0.5664, Loss G: 0.5575\n",
      "Epoch [8/50Loss D: 1.0107, Loss G: 0.1662\n",
      "Epoch [8/50Loss D: 0.6992, Loss G: 0.3394\n",
      "Epoch [8/50Loss D: 0.8356, Loss G: 0.2554\n",
      "Epoch [8/50Loss D: 0.7077, Loss G: 0.3312\n",
      "Epoch [8/50Loss D: 0.7578, Loss G: 0.3136\n",
      "Epoch [8/50Loss D: 0.7409, Loss G: 0.3181\n",
      "Epoch [8/50Loss D: 0.8114, Loss G: 0.2800\n",
      "Epoch [8/50Loss D: 0.6361, Loss G: 0.4276\n",
      "Epoch [8/50Loss D: 0.7635, Loss G: 0.3104\n",
      "Epoch [8/50Loss D: 0.8590, Loss G: 0.2322\n",
      "Epoch [8/50Loss D: 0.7528, Loss G: 0.3138\n",
      "Epoch [8/50Loss D: 0.7061, Loss G: 0.3554\n",
      "Epoch [8/50Loss D: 0.6523, Loss G: 0.4076\n",
      "Epoch [8/50Loss D: 0.7508, Loss G: 0.3452\n",
      "Epoch [8/50Loss D: 0.6700, Loss G: 0.3873\n",
      "Epoch [8/50Loss D: 0.8423, Loss G: 0.2406\n",
      "Epoch [8/50Loss D: 0.6658, Loss G: 0.3835\n",
      "Epoch [8/50Loss D: 0.6413, Loss G: 0.4239\n",
      "Epoch [8/50Loss D: 0.6900, Loss G: 0.3389\n",
      "Epoch [8/50Loss D: 0.8105, Loss G: 0.2687\n",
      "Epoch [8/50Loss D: 0.7342, Loss G: 0.3188\n",
      "Epoch [8/50Loss D: 0.6312, Loss G: 0.4198\n",
      "Epoch [8/50Loss D: 0.6070, Loss G: 0.4584\n",
      "Epoch [8/50Loss D: 0.6024, Loss G: 0.4965\n",
      "Epoch [8/50Loss D: 0.6906, Loss G: 0.3412\n",
      "Epoch [8/50Loss D: 0.8925, Loss G: 0.2154\n",
      "Epoch [8/50Loss D: 0.9306, Loss G: 0.1970\n",
      "Epoch [8/50Loss D: 0.7844, Loss G: 0.2975\n",
      "Epoch [8/50Loss D: 0.7690, Loss G: 0.3132\n",
      "Epoch [8/50Loss D: 0.7073, Loss G: 0.3670\n",
      "Epoch [8/50Loss D: 0.7153, Loss G: 0.3354\n",
      "Epoch [8/50Loss D: 0.8465, Loss G: 0.2542\n",
      "Epoch [8/50Loss D: 0.7022, Loss G: 0.3528\n",
      "Epoch [8/50Loss D: 0.6976, Loss G: 0.3919\n",
      "Epoch [8/50Loss D: 0.7024, Loss G: 0.3650\n",
      "Epoch [8/50Loss D: 0.7123, Loss G: 0.3346\n",
      "Epoch [8/50Loss D: 0.5824, Loss G: 0.4756\n",
      "Epoch [8/50Loss D: 0.8205, Loss G: 0.2663\n",
      "Epoch [8/50Loss D: 0.6641, Loss G: 0.3963\n",
      "Epoch [8/50Loss D: 0.8416, Loss G: 0.2582\n",
      "Epoch [8/50Loss D: 0.7273, Loss G: 0.3499\n",
      "Epoch [8/50Loss D: 0.6945, Loss G: 0.3590\n",
      "Epoch [8/50Loss D: 0.6752, Loss G: 0.3825\n",
      "Epoch [8/50Loss D: 0.7503, Loss G: 0.3058\n",
      "Epoch [8/50Loss D: 0.8899, Loss G: 0.2330\n",
      "Epoch [8/50Loss D: 0.6454, Loss G: 0.4058\n",
      "Epoch [8/50Loss D: 0.6796, Loss G: 0.3734\n",
      "Epoch [8/50Loss D: 0.7183, Loss G: 0.3414\n",
      "Epoch [8/50Loss D: 0.9228, Loss G: 0.1963\n",
      "Epoch [8/50Loss D: 0.7832, Loss G: 0.2858\n",
      "Epoch [8/50Loss D: 0.7769, Loss G: 0.3100\n",
      "Epoch [8/50Loss D: 0.7524, Loss G: 0.3032\n",
      "Epoch [8/50Loss D: 0.5847, Loss G: 0.4399\n",
      "Epoch [8/50Loss D: 0.7043, Loss G: 0.3355\n",
      "Epoch [8/50Loss D: 0.8370, Loss G: 0.2504\n",
      "Epoch [8/50Loss D: 0.7123, Loss G: 0.4189\n",
      "Epoch [8/50Loss D: 0.6639, Loss G: 0.3884\n",
      "Epoch [8/50Loss D: 0.7911, Loss G: 0.2766\n",
      "Epoch [8/50Loss D: 0.6146, Loss G: 0.4559\n",
      "Epoch [8/50Loss D: 1.0381, Loss G: 0.1541\n",
      "Epoch [8/50Loss D: 0.7912, Loss G: 0.2813\n",
      "Epoch [8/50Loss D: 0.7123, Loss G: 0.3604\n",
      "Epoch [8/50Loss D: 0.6699, Loss G: 0.3727\n",
      "Epoch [8/50Loss D: 0.7178, Loss G: 0.3621\n",
      "Epoch [8/50Loss D: 0.6589, Loss G: 0.3910\n",
      "Epoch [8/50Loss D: 0.5958, Loss G: 0.4599\n",
      "Epoch [8/50Loss D: 0.6702, Loss G: 0.3825\n",
      "Epoch [8/50Loss D: 0.6890, Loss G: 0.4052\n",
      "Epoch [8/50Loss D: 0.7734, Loss G: 0.3105\n",
      "Epoch [8/50Loss D: 0.7378, Loss G: 0.3116\n",
      "Epoch [8/50Loss D: 0.7291, Loss G: 0.3246\n",
      "Epoch [8/50Loss D: 0.6682, Loss G: 0.4107\n",
      "Epoch [8/50Loss D: 0.8500, Loss G: 0.2342\n",
      "Epoch [8/50Loss D: 0.6680, Loss G: 0.3727\n",
      "Epoch [8/50Loss D: 0.6087, Loss G: 0.4179\n",
      "Epoch [8/50Loss D: 0.7233, Loss G: 0.3312\n",
      "Epoch [8/50Loss D: 0.7543, Loss G: 0.3624\n",
      "Epoch [8/50Loss D: 0.7366, Loss G: 0.3277\n",
      "Epoch [8/50Loss D: 0.5984, Loss G: 0.4830\n",
      "Epoch [8/50Loss D: 0.8529, Loss G: 0.2369\n",
      "Epoch [8/50Loss D: 0.6459, Loss G: 0.3702\n",
      "Epoch [8/50Loss D: 0.8620, Loss G: 0.2344\n",
      "Epoch [8/50Loss D: 0.8190, Loss G: 0.2546\n",
      "Epoch [8/50Loss D: 0.6865, Loss G: 0.3505\n",
      "Epoch [8/50Loss D: 0.6003, Loss G: 0.4657\n",
      "Epoch [8/50Loss D: 0.6258, Loss G: 0.4275\n",
      "Epoch [8/50Loss D: 0.7369, Loss G: 0.3123\n",
      "Epoch [8/50Loss D: 0.7209, Loss G: 0.3318\n",
      "Epoch [8/50Loss D: 0.7686, Loss G: 0.3021\n",
      "Epoch [8/50Loss D: 0.8520, Loss G: 0.2552\n",
      "Epoch [8/50Loss D: 0.7824, Loss G: 0.3091\n",
      "Epoch [8/50Loss D: 0.6669, Loss G: 0.4087\n",
      "Epoch [8/50Loss D: 0.7990, Loss G: 0.2592\n",
      "Epoch [8/50Loss D: 0.6639, Loss G: 0.3986\n",
      "Epoch [8/50Loss D: 0.6865, Loss G: 0.3532\n",
      "Epoch [8/50Loss D: 0.8408, Loss G: 0.2590\n",
      "Epoch [8/50Loss D: 0.7430, Loss G: 0.3053\n",
      "Epoch [8/50Loss D: 0.6254, Loss G: 0.4175\n",
      "Epoch [8/50Loss D: 0.5579, Loss G: 0.5696\n",
      "Epoch [8/50Loss D: 0.6812, Loss G: 0.3788\n",
      "Epoch [8/50Loss D: 0.7810, Loss G: 0.3260\n",
      "Epoch [8/50Loss D: 0.6399, Loss G: 0.4497\n",
      "Epoch [8/50Loss D: 0.5986, Loss G: 0.4752\n",
      "Epoch [8/50Loss D: 0.7112, Loss G: 0.3275\n",
      "Epoch [8/50Loss D: 0.7404, Loss G: 0.3185\n",
      "Epoch [8/50Loss D: 0.8291, Loss G: 0.2521\n",
      "Epoch [8/50Loss D: 0.8272, Loss G: 0.2558\n",
      "Epoch [8/50Loss D: 0.6903, Loss G: 0.4059\n",
      "Epoch [8/50Loss D: 0.8693, Loss G: 0.2327\n",
      "Epoch [8/50Loss D: 0.7946, Loss G: 0.2758\n",
      "Epoch [8/50Loss D: 0.6260, Loss G: 0.4667\n",
      "Epoch [8/50Loss D: 0.8017, Loss G: 0.2732\n",
      "Epoch [8/50Loss D: 0.7630, Loss G: 0.3452\n",
      "Epoch [8/50Loss D: 0.9034, Loss G: 0.2268\n",
      "Epoch [8/50Loss D: 0.5801, Loss G: 0.5181\n",
      "Epoch [8/50Loss D: 0.6247, Loss G: 0.4231\n",
      "Epoch [8/50Loss D: 0.6842, Loss G: 0.3805\n",
      "Epoch [8/50Loss D: 0.7709, Loss G: 0.2869\n",
      "Epoch [8/50Loss D: 0.7744, Loss G: 0.3211\n",
      "Epoch [8/50Loss D: 0.6929, Loss G: 0.3594\n",
      "Epoch [8/50Loss D: 0.6682, Loss G: 0.3971\n",
      "Epoch [8/50Loss D: 0.7817, Loss G: 0.2866\n",
      "Epoch [8/50Loss D: 0.7777, Loss G: 0.3068\n",
      "Epoch [8/50Loss D: 0.7622, Loss G: 0.3915\n",
      "Epoch [8/50Loss D: 0.7494, Loss G: 0.3152\n",
      "Epoch [8/50Loss D: 0.6702, Loss G: 0.3521\n",
      "Epoch [8/50Loss D: 0.8010, Loss G: 0.2854\n",
      "Epoch [8/50Loss D: 0.5844, Loss G: 0.4836\n",
      "Epoch [8/50Loss D: 0.6968, Loss G: 0.3629\n",
      "Epoch [8/50Loss D: 0.6711, Loss G: 0.3721\n",
      "Epoch [8/50Loss D: 0.8457, Loss G: 0.2443\n",
      "Epoch [8/50Loss D: 0.6748, Loss G: 0.3518\n",
      "Epoch [8/50Loss D: 0.7004, Loss G: 0.3250\n",
      "Epoch [8/50Loss D: 0.7396, Loss G: 0.3136\n",
      "Epoch [8/50Loss D: 0.7228, Loss G: 0.3804\n",
      "Epoch [8/50Loss D: 0.6087, Loss G: 0.4576\n",
      "Epoch [8/50Loss D: 0.6602, Loss G: 0.3823\n",
      "Epoch [8/50Loss D: 0.7810, Loss G: 0.2847\n",
      "Epoch [8/50Loss D: 0.7719, Loss G: 0.3119\n",
      "Epoch [8/50Loss D: 0.7381, Loss G: 0.3149\n",
      "Epoch [8/50Loss D: 0.6932, Loss G: 0.3626\n",
      "Epoch [8/50Loss D: 0.5939, Loss G: 0.4524\n",
      "Epoch [8/50Loss D: 0.6107, Loss G: 0.4362\n",
      "Epoch [8/50Loss D: 0.7475, Loss G: 0.2979\n",
      "Epoch [8/50Loss D: 0.6937, Loss G: 0.3712\n",
      "Epoch [8/50Loss D: 0.9323, Loss G: 0.2156\n",
      "Epoch [8/50Loss D: 0.7922, Loss G: 0.2730\n",
      "Epoch [8/50Loss D: 0.7741, Loss G: 0.2960\n",
      "Epoch [8/50Loss D: 0.6174, Loss G: 0.5124\n",
      "Epoch [8/50Loss D: 1.0098, Loss G: 0.1627\n",
      "Epoch [8/50Loss D: 1.0106, Loss G: 0.1669\n",
      "Epoch [8/50Loss D: 0.7695, Loss G: 0.2913\n",
      "Epoch [8/50Loss D: 0.7890, Loss G: 0.2839\n",
      "Epoch [8/50Loss D: 0.7080, Loss G: 0.3491\n",
      "Epoch [8/50Loss D: 0.9265, Loss G: 0.2032\n",
      "Epoch [8/50Loss D: 0.9776, Loss G: 0.1942\n",
      "Epoch [8/50Loss D: 0.8191, Loss G: 0.2690\n",
      "Epoch [8/50Loss D: 0.7449, Loss G: 0.3432\n",
      "Epoch [8/50Loss D: 0.6260, Loss G: 0.4740\n",
      "Epoch [9/50Loss D: 0.6904, Loss G: 0.3419\n",
      "Epoch [9/50Loss D: 0.6572, Loss G: 0.3938\n",
      "Epoch [9/50Loss D: 0.6827, Loss G: 0.3952\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51249/2612307417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mopt_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    for batch_idx, (real,_) in enumerate(loader):\n",
    "        #current batch_size\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        #Faux echantillons\n",
    "        #Gnration de N=batch_size bruits \n",
    "        noise = torch.randn(batch_size,input_dim,1,1).to(device)\n",
    "        #Gnration des \"faux\"  partir du bruit\n",
    "        fake = gen(noise)\n",
    "        #Passage des faux dans le discriminateur\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        #Passage dans la loss discriminateur et generateur\n",
    "        \n",
    "        loss_G = criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "        \n",
    "        #On continue en mettant les oprations propres au discriminateur ensembles\n",
    "        loss_Dfake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        \n",
    "        #Vrais chantillons\n",
    "        real = real.view(-1,1,28,28).to(device)\n",
    "        #Passage des vrais dans le discriminateur\n",
    "        disc_real = disc(real).view(-1)\n",
    "        #Passage dans la loss discriminateur\n",
    "        loss_Dreal = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        #Calcul de la loss totale\n",
    "        loss_D = (loss_Dreal+loss_Dfake)/2\n",
    "        #Update des poids du discriminateur et du gnrateur\n",
    "        disc.zero_grad()\n",
    "        loss_D.backward(retain_graph=True)\n",
    "             \n",
    "        \n",
    "        gen.zero_grad()\n",
    "        loss_G.backward()\n",
    "        \n",
    "        opt_disc.step() \n",
    "        opt_gen.step()\n",
    "    \n",
    "        if (batch_idx%10)==0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epoch}\"\n",
    "                f\"Loss D: {loss_D:.4f}, Loss G: {loss_G:.4f}\"\n",
    "                )\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1,1,28,28)\n",
    "                real,_=next(iter(loader))\n",
    "                data = real.reshape(-1,1,28,28)\n",
    "                \n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist fake images\",img_grid_fake,global_step=epoch*1500+batch_idx\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist real images\",img_grid_real,global_step=epoch*1500+batch_idx\n",
    "                )\n",
    "                writer_real.flush()\n",
    "                writer_fake.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_19028/1513586310.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m    125\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'disc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 127\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19028/1513586310.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(max_changes, change_loss)\u001b[0m\n",
      "\u001b[1;32m    118\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gen'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    119\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'gen'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mLoss_G\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLoss_D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mLoss_G\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mchange_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    122\u001b[0m                 \u001b[0mchanges\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/tmp/ipykernel_19028/1513586310.py\u001b[0m in \u001b[0;36mtrain_gen\u001b[0;34m(change_loss)\u001b[0m\n",
      "\u001b[1;32m     73\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     74\u001b[0m         \u001b[0;31m#Gnration des \"faux\"  partir du bruit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;31m#Passage des faux dans le discriminateur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     77\u001b[0m         \u001b[0mdisc_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
      "\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/tmp/ipykernel_19028/4130853559.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n",
      "\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
      "\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n",
      "\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
      "\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n",
      "\u001b[1;32m    914\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n",
      "\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 916\u001b[0;31m         return F.conv_transpose2d(\n",
      "\u001b[0m\u001b[1;32m    917\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    918\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def output(Loss_D,Loss_G,changes,max_changes):\n",
    "    print(\n",
    "        f\"Epoch [{changes}/{max_changes}\"\n",
    "        f\"Loss D: {Loss_D:.4f}, Loss G: {Loss_G:.4f}\"\n",
    "        )\n",
    "    with torch.no_grad():\n",
    "        fake = gen(fixed_noise).reshape(-1,1,28,28)\n",
    "        real,_=next(iter(loader))\n",
    "        data = real.reshape(-1,1,28,28)\n",
    "        \n",
    "        img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "        img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "        writer_fake.add_image(\n",
    "            \"Mnist fake images\",img_grid_fake,global_step=changes\n",
    "        )\n",
    "        writer_real.add_image(\n",
    "            \"Mnist real images\",img_grid_real,global_step=changes\n",
    "        )\n",
    "        writer_real.flush()\n",
    "        writer_fake.flush()\n",
    "        \n",
    "def train_disc(change_loss):\n",
    "    for batch_idx, (real,_) in enumerate(loader):\n",
    "\n",
    "        \n",
    "        #current batch_size\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        #Faux echantillons\n",
    "        #Gnration de N=batch_size bruits \n",
    "        noise = torch.randn(batch_size,input_dim,1,1).to(device)\n",
    "        #Gnration des \"faux\"  partir du bruit\n",
    "        fake = gen(noise)\n",
    "        #Passage des faux dans le discriminateur\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        #Passage dans la loss discriminateur et generateur\n",
    "        \n",
    "\n",
    "        \n",
    "        #On continue en mettant les oprations propres au discriminateur ensembles\n",
    "        loss_Dfake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        \n",
    "        #Vrais chantillons\n",
    "        real = real.view(-1,1,28,28).to(device)\n",
    "        #Passage des vrais dans le discriminateur\n",
    "        disc_real = disc(real).view(-1)\n",
    "        #Passage dans la loss discriminateur\n",
    "        loss_Dreal = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        #Calcul de la loss totale\n",
    "        loss_D = (loss_Dreal+loss_Dfake)/2\n",
    "            \n",
    "        #Update des poids du discriminateur\n",
    "        disc.zero_grad()\n",
    "        loss_D.backward()\n",
    "        opt_disc.step()\n",
    "        \n",
    "        if loss_D.detach().numpy()<change_loss:\n",
    "            break\n",
    "        \n",
    "    loss_G = criterion(disc_fake, torch.ones_like(disc_fake))   \n",
    "     \n",
    "    return loss_G.detach().numpy(),loss_D.detach().numpy()\n",
    "\n",
    "def train_gen(change_loss):\n",
    "    for batch_idx, (real,_) in enumerate(loader):\n",
    "\n",
    "        \n",
    "        #current batch_size\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        #Faux echantillons\n",
    "        #Gnration de N=batch_size bruits \n",
    "        noise = torch.randn(batch_size,input_dim,1,1).to(device)\n",
    "        #Gnration des \"faux\"  partir du bruit\n",
    "        fake = gen(noise)\n",
    "        #Passage des faux dans le discriminateur\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        #Passage dans la loss discriminateur et generateur\n",
    "        loss_G = criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "            \n",
    "            \n",
    "        #Update des poids du discriminateur\n",
    "        gen.zero_grad()\n",
    "        loss_G.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        if loss_G.detach().numpy()<change_loss:\n",
    "            break\n",
    "    \n",
    "    loss_Dfake = criterion(disc_fake, torch.zeros_like(disc_fake))  \n",
    "    #Vrais chantillons\n",
    "    real = real.view(-1,1,28,28).to(device)\n",
    "    #Passage des vrais dans le discriminateur\n",
    "    disc_real = disc(real).view(-1)\n",
    "    #Passage dans la loss discriminateur\n",
    "    loss_Dreal = criterion(disc_real, torch.ones_like(disc_real))\n",
    "    #Calcul de la loss totale\n",
    "    loss_D = (loss_Dreal+loss_Dfake)/2\n",
    "\n",
    "        \n",
    "    return loss_G.detach().numpy(),loss_D.detach().numpy()\n",
    "    \n",
    "\n",
    "#writer\n",
    "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")\n",
    "        \n",
    "def train(max_changes=10,change_loss=0.01):\n",
    "    state='disc'\n",
    "    changes=0\n",
    "    while changes < max_changes :\n",
    "        if state=='disc':\n",
    "            Loss_G,Loss_D=train_disc(change_loss)\n",
    "            if Loss_D < change_loss:\n",
    "                changes+=1\n",
    "                if changes%25==0:\n",
    "                    output(Loss_D,Loss_G,changes,max_changes)\n",
    "                state='gen'\n",
    "        elif state=='gen':\n",
    "            Loss_G,Loss_D=train_gen(change_loss)\n",
    "            if Loss_G < change_loss:\n",
    "                changes+=1\n",
    "                if changes%25==0:\n",
    "                    output(Loss_D,Loss_G,changes,max_changes)\n",
    "                state='disc'\n",
    "            \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(disc.state_dict(),'weights_disc')\n",
    "torch.save(gen.state_dict(),'weights_gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
